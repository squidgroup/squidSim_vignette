[["index.html", "The {squidSim} R Package Vignette Version 0.2.2 The {squidSim} R package", " The {squidSim} R Package Vignette Version 0.2.2 Joel Pick 2025-09-13 The {squidSim} R package The {squidSim} R package is designed to simplify data simulation from a highly flexible set of models, including: Correlated and interacting predictor variables Non-Gaussian response variables (Poisson and binomial) Crossed and nested hierarchical structures Random intercepts and slopes Univariate and multivariate data Within level-specific residual variance (DHGLMs) Additive genetic effects (animal models) Phylogenetic effects with different models of evolution Temporal and spatial autocorrelation Missing data (MNAR, MAR and MCAR) Temporal sampling The main idea is that anything you can model using a linear mixed effect model framework (assuming underlying multivariate normality) you can simulate using the {squidSim} package. Why use {squidSim}? Starting with simulations can seem like a daunting task. The {squidSim} R package is designed to facilitate that transition, and to focus attention on the data structure and parameters needed for simulation, rather than programming knowledge. {squidSim} also provides a useful tool for experienced programmers. One problematic aspect of collaborative coding (or reviewing someone else’s code) is that many people have very contrasting programming styles. A major motivation for the {squidSim} package is that it provides a consistent framework for simulations, which can be interpreted by many people rather than having to decipher someone’s personal code. Using the vignette If you are new to using the {squidSim} package, we recommend that you read Sections 1 and 2 to familiarise yourself with the {squidSim} package before moving onto the more advanced topics. The later sections assume a certain level of understanding of how the functions work. The vignette assumes that you have a working knowledge of R, in particular being comfortable using vectors, matrices and lists. Installation The {squidSim} package is currently only available on github: devtools::install_github(&quot;squidgroup/squidSim&quot;) library(squidSim) Citing {squidSim} R packages take a lot of investment to create and maintain. We would therefore appreciate it if you cited squidSim when you used it. Please cite our pre-print: Issues and bugs It would be great if you could report any suggestions, issues or bugs; here for issues relating to the package, and here for issues relating to this vignette. It is worth checking to see if anyone else has a similar problem first, and adding comments to their issue, before starting a new one. "],["simulate_population-function.html", "simulate_population() function", " simulate_population() function The heart of the {squidSim} R package is the simulate_population() function, which we can use to simulate hierarchical, population level data. We provide the function with a set of parameters, a hierarchical data structure (if we are simulating hierarchical data), and various other optional arguments, which are listed below. The simulate_population() function simulates predictors at each hierarchical level, using provided mean and variance-covariance (vcov) parameters, from a multivariate normal distribution. These predictors are then scaled by the beta parameters, and added together to create the response. The arguments that can be provided to the simulate_population() function (along with their defaults) are: simulate_population( data_structure, n, parameters, n_response=1, response_names, family=&quot;gaussian&quot;, link=&quot;identity&quot;, model, known_predictors, pedigree, pedigree_type, phylogeny, phylogeny_type, cov_str, sample_type, sample_param, n_pop=1 ) Each of these will be covered in more detail in the following sections. Briefly, n and data_structure refer to the size and structure of the data being simulated - data_structure is covered in more detail in Section 2. parameters is a list of parameters to be used in the simulation and is described in detail in Section 1. n_response refers the number of response variable to be simulated and is covered in detail in the section on multivariate models (Section 3). response_names controls what the simulated response variables are named, and is described in Sections 1 and 3. family and link refer to simulating non Gaussian response variables and are covered in Section 1.6. model allows for the specification of more complex models and is covered in Section 1.7. known_predictors allows for existing data to be incorporated into the simulations and is covered in 1.5. pedigree and pedigree_type relate to simulating genetic effects and are covered in Section 4, phylogeny and phylogeny_type relate to simulating phylogenetic effects and are covered in Section 5 and cov_str relates to simulating a general covariance structure and is covered in multiple sections, including 4, 5, 6.3 and 6.4. sample_type and sample_param relate to different sampling methods and are covered in Section 7 n_pop relates to the number of populations, or datasets, that you want to simulate for each parameter set. This is covered in Section 1.8. "],["terminology-and-notation.html", "Terminology and notation", " Terminology and notation We try to be consistent as possible throughout the vignette with our terminology and notation. {squidSim} refers to an R package simulate_population() refers to a function parameters refers more generally to code "],["mathematical-notation.html", "Mathematical Notation", " Mathematical Notation We try to use a consistent notation in equations throughout the manuscript, which we try to explain as we go. For the sake of clarity we have outlined everything here. General rules Small letters (e.g. \\(x\\)) denote scalars Bold, small letters (e.g. \\(\\boldsymbol{x}\\)) denote vectors Capital letters (e.g. \\(X\\)) denote matrices Letter/Symbol Usage \\(\\sigma\\) standard deviation \\(\\Sigma\\) covariance matrix \\(\\sigma_{x_1x_2}\\) covariance between variables x1 and x2 \\(\\mu\\) mean \\(\\epsilon\\) residual \\(\\beta\\) slope \\(x\\) predictor variable \\(y\\) response variable Notation for a linear mixed model There are several ways to write out an equation for a linear model. First, we can write out all the different variables: \\(y_i = \\beta_0 + \\beta_1 x_{1,i} + \\beta_2 x_{2,i} + \\beta_3 x_{3,i} + \\epsilon_i\\) where each observation (denoted by the index \\(i\\)) of our response variable (\\(y_i\\)) is the sum of an intercept (\\(\\beta_0\\); value of the response when the predictor variables are all 0), the associated value of our predictor variables (\\(x_{1i}\\), \\(x_{2i}\\), \\(x_{3i}\\); which also vary at the level of the observation), each with a certain magnitude and direction of their effect (effect size or slope; \\(\\beta_1\\) etc), and some unexplained, residual variation (\\(\\epsilon_i\\)). We can also write this in matrix notation: \\(\\boldsymbol{y} = X\\boldsymbol{\\beta} + \\boldsymbol{\\epsilon}\\) where \\(X\\) is a matrix of predictors and \\(\\boldsymbol{\\beta}\\) is a (column) vector of slopes/effect sizes. This matrix notation is a bit more compact and relates most easily the structure of the simulate_population() function. However it becomes more complex when we have things varying at different levels, as we have to start getting design matrices for the random effects involved e.g. \\(\\boldsymbol{y} = X\\boldsymbol{\\beta} + Z\\boldsymbol{u} + \\boldsymbol{\\epsilon}\\) which we would rather avoid here as it has little relation to the squidSim code. We can therefore combine the index and matrix notation. This is maybe a little more complex, but it’s compact and flexible and relates well to the simulate_population() function. \\(y_{i} = \\beta_0 + \\boldsymbol{x}_{i} \\boldsymbol{\\beta} + \\epsilon_{i}\\) where \\(\\boldsymbol{x}_{i}\\) is the \\(i\\)th row of \\(X\\). I have deliberately separated the intercept (\\(\\beta_0\\)) out here, for the purpose of comparing with the structure of simulate_population(). Then for models that have predictors vary at different levels we can have \\(y_{ij} = \\beta_0 + \\boldsymbol{x}_{i} \\boldsymbol{\\beta}_x + \\boldsymbol{u}_j \\boldsymbol{\\beta}_u + \\epsilon_{ij}\\) Instead of having predictors at different levels, we might have ‘random effects’ \\(y_{ij} = \\beta_0 + \\boldsymbol{x}_{i} \\boldsymbol{\\beta}_x + u_j + \\epsilon_{ij}\\) at multiple levels \\(y_{ijk} = \\beta_0 + \\boldsymbol{x}_{i} \\boldsymbol{\\beta}_x + u_j + w_k + \\epsilon_{ijk}\\) Distributions We can write distribution equations as: \\(x_{1i} \\sim \\mathcal{N}(\\mu, \\sigma^2)\\) or \\(\\boldsymbol{x}_i \\sim \\mathcal{N}(\\boldsymbol{\\mu}_x, \\Sigma_x)\\) Interactions / Random regression \\(y_{ij} = \\beta_0 + \\beta_1x_{i} + u_{1j} + x_{i}u_{2j} + \\epsilon_{ij}\\) \\(x_{i} \\sim \\mathcal{N}(\\mu_x, \\sigma^2_x)\\) \\(\\boldsymbol{u}_j \\sim \\mathcal{N}(0, \\Sigma_u)\\) \\(\\epsilon_{ij} \\sim \\mathcal{N}(0, \\sigma^2_{\\epsilon})\\) Multi-response \\(\\boldsymbol{y}_{ij} = \\boldsymbol{\\beta}_0 + \\boldsymbol{x}_{i} B_x + \\boldsymbol{u}_j + \\boldsymbol{\\epsilon}_{ij}\\) \\(\\boldsymbol{x}_i \\sim \\mathcal{N}(\\boldsymbol{\\mu}_x, \\Sigma_x)\\) \\(\\boldsymbol{u}_j \\sim \\mathcal{N}(0, \\Sigma_u)\\) \\(\\boldsymbol{\\epsilon}_{ij} \\sim \\mathcal{N}(0, \\Sigma_{\\epsilon})\\) where \\(\\boldsymbol{\\beta}_0\\) is a vector of intercepts of length q (number of responses) \\(B\\) is a \\(p*q\\) (p - number of predictors) matrix of \\(\\beta\\)s "],["1-linearmod.html", "1 Simulating from linear models", " 1 Simulating from linear models In this section, we will look at simulating simple data from linear models, to familiarise ourselves with how {squidSim} works. "],["1.1-simple-linear-model.html", "1.1 Simple Linear Model", " 1.1 Simple Linear Model We will start simulating data without any hierarchical structure, i.e. everything varies at the level of the observation. Let’s imagine a situation where body mass is affected by some environmental variables - temperature, rainfall and wind. We can write this out in the form of a linear model: \\[ y_i = \\beta_0 + \\beta_1 x_{1i} + \\beta_2 x_{2i} + \\beta_3 x_{3i} + \\epsilon_i \\] , where each observation (denoted by the index \\(i\\)) of our response variable (\\(y_i\\)) is the sum of an intercept (\\(\\beta_0\\); value of the response when the predictor variables are all 0), the associated value of our predictor variables (\\(x_{1i}\\), \\(x_{2i}\\), \\(x_{3i}\\); which also vary at the level of the observation), each with a certain magnitude and direction of their effect (effect size or slope; \\(\\beta_1\\) etc), and some unexplained, residual variation (\\(\\epsilon_i\\)). We can write this in more compact notation, \\[ y_{i} = \\beta_0 + \\boldsymbol{x}_{i} \\boldsymbol{\\beta} + \\epsilon_{i} \\] where \\(\\boldsymbol{x}_{i}\\) is a (row) vector of \\(x_{1i}\\), \\(x_{2i}\\) \\(x_{3i}\\) etc, or equivalently row \\(i\\) in the matrix of predictors \\(X\\), \\[ \\boldsymbol{x}_{i} = \\begin{bmatrix} x_{1i} &amp; x_{2i} &amp; x_{3i} \\end{bmatrix} \\] and \\(\\boldsymbol{\\beta}\\) is a (column) vector of slopes/effect sizes \\[ \\boldsymbol{\\beta} = \\begin{bmatrix} \\beta_1 \\\\ \\beta_2 \\\\ \\beta_3 \\end{bmatrix} \\] We will use this notation throughout the vignette, as it is a bit more compact, relates most easily the structure of the simulate_population() function, and can incorporate the flexibility needed for the different model structures. We assume that these predictor variables are multivariate normally distributed, with given means (\\(\\mu\\)) and a covariance structure (\\(\\Sigma_x\\)), and the residuals are normally distributed with a given variance (\\(\\sigma^2_\\epsilon\\)) \\[ \\boldsymbol{x}_i \\sim \\mathcal{N}(\\boldsymbol{\\mu}_x, \\Sigma_x) \\] \\[ \\epsilon_i \\sim \\mathcal{N}(0,\\sigma^2_\\epsilon) \\] where \\[ \\boldsymbol{\\mu}_x = \\begin{bmatrix} \\mu_{x_1} \\\\ \\mu_{x_2} \\\\ \\mu_{x_3} \\end{bmatrix} , \\Sigma_x = \\begin{bmatrix} \\sigma^2_{x_1} &amp; \\sigma_{x_1x_2} &amp; \\sigma_{x_1x_3}\\\\ \\sigma_{x_1x_2} &amp; \\sigma^2_{x_2} &amp; \\sigma_{x_2x_3}\\\\ \\sigma_{x_1x_3} &amp; \\sigma_{x_2x_3} &amp; \\sigma^2_{x_3} \\end{bmatrix} \\] The key to simulating data using the squidSim package is correctly specifying the parameters (from the equations above that would be \\(\\beta_0\\), \\(\\boldsymbol{\\beta}\\), \\(\\boldsymbol{\\mu}_x\\), \\(\\Sigma_x\\), \\(\\sigma^2_\\epsilon\\)). These parameters are given to the simulate_population function as a nested list. Within the main parameter list, there are named lists corresponding to different hierarchical levels, containing the parameters for the predictors at that level - here we are just focussing on the observation level (see Section 2 for examples with hierarchical structure). Parameters for the residual must be specified, all other levels are optional (they revert to defaults values; beta=1, mean=0, vcov=1. In addition to the named lists relating to hierarchical levels, a vector for intercepts and a list for interactions can be added. Intercepts are demonstrated in the examples below, and interactions in Section 1.3. Many of the components in the parameter list don’t need to be specified and default values will be created. Let’s simulate from the above model. First, we can specify a sample size or data_structure. As we don’t have any hierarchical data structure yet (see Section 2), we have to specify the sample size with the n argument to the simulate_population function (e.g. 2000). simulate_population( n=2000, ... ) We can also give the response (\\(\\boldsymbol{y}\\)) variable a name, body_mass (this is not needed, and defaults to y if not specified). simulate_population( n=2000, response_name = &quot;body_mass&quot;, ... ) We then need to add in our parameter list: simulate_population( n=2000, response_name = &quot;body_mass&quot;, parameters = list( ... ) ) To fill in our parameter list, lets think about our model \\[ y_{i} = \\color{red}{\\beta_0}+ \\color{blue}{\\boldsymbol{x}_{i} \\boldsymbol{\\beta}} + \\color{orange}{\\epsilon_{i}} \\] \\[ \\boldsymbol{x}_i \\sim \\mathcal{N}(\\boldsymbol{\\mu}_x, \\Sigma_x) \\] \\[ \\epsilon_i \\sim \\mathcal{N}(0,\\sigma^2_\\epsilon) \\] or in words: intercept + observation level predictors + residual These names correspond to names in our parameter list. To simulate our environmental predictors that vary at the level of the observation, we can use the observation slot in the parameter list, as well as specifying an intercept and residual variance in the intercept and residual slots, respectively. The global intercept (\\(\\beta_0\\)) is given by specifying an intercept vector in the parameter list e.g. intercept=10 For both observation and residual we create a list containing the respective parameters. For the observation list, we can specify the names of these variables as a vector (these can be anything - I like giving things actual names, but could also be x1, x2 and x3) and, in the simplest case, the \\(\\beta\\) values as a vector. observation = list( names = c(&quot;temperature&quot;,&quot;rainfall&quot;, &quot;wind&quot;), beta = c(0.5,-0.3, 0.4) ) By default, these predictors are simulated as i.i.d. unit normals (mean=0, var=1, cov=0), so \\[ \\boldsymbol{\\mu}_x = \\begin{bmatrix} 0 \\\\ 0 \\\\ 0 \\end{bmatrix} , \\Sigma_x = \\begin{bmatrix} 1 &amp; 0 &amp; 0\\\\ 0 &amp; 1 &amp; 0\\\\ 0 &amp; 0 &amp; 1 \\end{bmatrix} \\] Note that the order of the names and betas has to match. We can then specify the residual variance, here as 0.8 (but can be anything). vcov refers to the variance-covariance matrix, which for the residuals is only a single variance until we have multiple response variables (Section 3). residual = list( vcov = 0.8 ) We can then put this all together: squid_data &lt;- simulate_population( n=2000, response_name = &quot;body_mass&quot;, parameters = list( intercept=10, observation = list( names = c(&quot;temperature&quot;,&quot;rainfall&quot;, &quot;wind&quot;), beta = c(0.5,-0.3, 0.4) ), residual = list( vcov = 0.8 ) ) ) Let’s compare the code back to the model using colors to link equation to code: \\[ y_{i} = \\color{red}{\\beta_0}+ \\color{blue}{\\boldsymbol{x}_{i} \\boldsymbol{\\beta}} + \\color{orange}{\\epsilon_{i}} \\] \\[ \\color{blue}{\\boldsymbol{x}_i \\sim \\mathcal{N}(\\boldsymbol{\\mu}_x, \\Sigma_x)} \\] \\[ \\color{orange}{\\epsilon_i \\sim \\mathcal{N}(0,\\sigma^2_\\epsilon)} \\] parameters = list(    intercept = 10,    observation = list(      names = c(“temperature”,“rainfall”, “wind”),      beta = c(0.5,-0.3, 0.4)    ),    residual = list(      vcov = 0.8    ) ) This generates a squid object, which when run returns a friendly message: squid_data ## Data simulated using squid ## ## /\\ ## / \\ ## / /\\ \\ ## \\/ \\/ ## / \\ ## | | ## | | ## 0 | | 0 ## / \\____/ \\ ## { __/( )\\__ } ## \\___/__\\_\\/_/__\\___/ ## / / / / \\ \\ \\ \\ ## / / / { } \\ \\ \\ ## { { / \\ / \\ } } ## } \\ 0 0 / { ## 0_/ { \\_0 0_/ } \\_0 ## \\ / ## } { ## / \\ ## 0 0 and contains all our simulation parameters as well as the simulated data. At this point we want to be able to access the simulated data. There are then some further functions which we can use to access the data and simulation parameters. We can extract the simulated data using get_population_data() The generated response is returned, along with simulated predictors and the data structure (not relevant here). data &lt;- get_population_data(squid_data) head(data) ## body_mass temperature rainfall wind residual squid_pop ## 1 10.187011 2.4800342 0.455257003 0.7825594 -1.2294526 1 ## 2 10.949223 -0.2569207 -1.474704317 0.3857166 0.4809849 1 ## 3 10.845240 0.2189803 1.463922216 -0.8564840 1.5175202 1 ## 4 9.916527 0.7198543 -1.037817017 2.3682777 -1.7020568 1 ## 5 10.216552 1.7756108 -0.003199892 -0.1130542 -0.6269915 1 ## 6 10.054326 1.2120665 0.558004447 0.8376667 -0.7193723 1 Later on we will explore how to simulate data for multiple populations with the same parameters (Section 1.8). squid_pop is an identifier for the population number, but is not relevant here. We can plot what we have simulated: library(scales) par(mfrow=c(1,3)) plot(body_mass ~ temperature + rainfall + wind, data, pch=19, cex=0.5, col=alpha(1,0.5)) and run a linear model to check that we get back the betas that we simulated: coef(lm(body_mass ~ temperature + rainfall + wind,data)) ## (Intercept) temperature rainfall wind ## 9.9898809 0.4891688 -0.3473308 0.3994893 We can also check the means and variances of the predictors predictors &lt;- data[,c(&quot;temperature&quot;,&quot;rainfall&quot;,&quot;wind&quot;)] colMeans(predictors) ## temperature rainfall wind ## 0.02084866 -0.02319050 0.04471757 cov(predictors) ## temperature rainfall wind ## temperature 1.03670554 -0.035961509 -0.028953762 ## rainfall -0.03596151 0.978340502 -0.003275084 ## wind -0.02895376 -0.003275084 1.017055449 It’s worth noting that these values are not exactly what we simulated. That is to be expected - simulation involves randomly generating data, which means that here will be stochasticity in the simulated sample, and in our estimates of the underlying parameters. 1.1.1 Adding more information about the predictors We can also specify the predictors as having different means and variances. In the observation list, mean and vcov specify the means and covariance matrix of the predictors. If the predictors were uncorrelated, we can just specify the variances as a vector (the diagonal elements of the covariance matrix), and the function assumes the covariances are 0 (see section 1.2 for correlated predictors). Below we have three predictors, temperature, rainfall and wind, with means 10, 1 and 20 respectively, variances 1, 0.1 and 2, respectively, and betas 0.5,-3 and 0.4, a residual variance 0.8 and a global intercept of 10: \\[ y_{i} = \\beta_0+ \\boldsymbol{x}_{i} \\boldsymbol{\\beta} + \\epsilon_{i} \\] \\[ \\boldsymbol{x}_i \\sim \\mathcal{N}(\\boldsymbol{\\mu}_x, \\Sigma_x) \\] \\[ \\epsilon_i \\sim \\mathcal{N}(0,\\sigma^2_\\epsilon) \\] \\[ \\color{red}{\\beta_0=10} , \\color{blue}{\\boldsymbol{\\mu}_x = \\begin{bmatrix} 10 \\\\ 1 \\\\ 20 \\end{bmatrix}} , \\color{CornflowerBlue}{\\Sigma_x = \\begin{bmatrix} 1 &amp; 0 &amp; 0\\\\ 0 &amp; 0.1 &amp; 0\\\\ 0 &amp; 0 &amp; 2 \\end{bmatrix}} , \\color{purple}{\\boldsymbol{\\beta} = \\begin{bmatrix} 0.5 \\\\ -3 \\\\ 0.4 \\end{bmatrix}} , \\color{orange}{\\sigma^2_\\epsilon=0.8} \\]    squid_data &lt;- simulate_population(      n=2000,      response_name = “body_mass”,      parameters = list(        intercept = 10,        observation = list(          names = c(“temperature”,“rainfall”, “wind”),          mean = c(10,1,20),          vcov = c(1,0.1,2),          beta = c(0.5,-3, 0.4)        ),        residual = list(          vcov = 0.8        )      )    ) data &lt;- get_population_data(squid_data) coef(lm(body_mass ~ temperature + rainfall + wind, data)) ## (Intercept) temperature rainfall wind ## 10.6351760 0.4610888 -3.0227161 0.3875934 library(scales) par(mfrow=c(1,3)) plot(body_mass ~ temperature + rainfall + wind, data, pch=19, cex=0.5, col=alpha(1,0.5)) Again, we can check that the means and variances of the predictors are being simulated as we think they should be predictors &lt;- data[,c(&quot;temperature&quot;,&quot;rainfall&quot;,&quot;wind&quot;)] colMeans(predictors) ## temperature rainfall wind ## 9.971433 1.005550 19.958695 cov(predictors) ## temperature rainfall wind ## temperature 0.977831756 -0.004972014 0.027147642 ## rainfall -0.004972014 0.100500727 -0.003564289 ## wind 0.027147642 -0.003564289 1.919863567 It can be complicated to keep up with how these different values combine to give the mean and variance of the response. To help with this, the simulated_variance() function calculates the expected mean and variance of the response variable, as well as breaking down the contribution of different predictors and hierarchical levels to the these. simulated_variance(squid_data) ## Contribution of the simulated predictors to the mean and variance in the response ## ## Simulated Mean: 20 ## Simulated Variance: 2.27 ## ## Contribution of different hierarchical levels to grand mean and variance: ## mean var ## intercept 10 0.00 ## observation 10 1.47 ## residual 0 0.80 ## ## ## Contribution of different predictors to grand mean and variance: ## mean var ## intercept 10 0.00 ## temperature 5 0.25 ## rainfall -3 0.90 ## wind 8 0.32 ## residual 0 0.80 "],["1.2-corpred.html", "1.2 Correlated predictors", " 1.2 Correlated predictors We can also simulate correlations between these predictors, as vcov specifies the variance/covariance matrix of the predictors. squid_data &lt;- simulate_population( n=2000, response_name = &quot;body_mass&quot;, parameters=list( intercept=10, observation=list( names=c(&quot;temperature&quot;,&quot;rainfall&quot;, &quot;wind&quot;), mean = c(10,1 ,20), vcov =matrix(c( 1, 0, 1, 0,0.1,0, 1, 0, 2 ), nrow=3 ,ncol=3,byrow=TRUE), beta =c(0.5,-3,0.4) ), residual=list( vcov=1 ) ) ) data &lt;- get_population_data(squid_data) library(scales) par(mfrow=c(1,3)) plot(body_mass ~ temperature + rainfall + wind, data, pch=19, cex=0.5, col=alpha(1,0.5)) coef(lm(body_mass ~ temperature + rainfall + wind, data)) ## (Intercept) temperature rainfall wind ## 9.8512456 0.4947747 -3.0476278 0.4139908 div.blue { background-color:#fcba03; border-radius: 5px; padding: 20px;} Matrices in R To code a matrix in R we use the matrix function (see ?matrix). This takes a vector of values, and arranges then in a matrix, with dimensions specified with nrow and ncol. By default it fills the matrix by column, which can be changed to per row, by specifying byrow=TRUE. For big matrices this can be petty annoying. TheTri2M() function from the package MCMCglmm allows you to just give the lower or upper half of the matrix, and it will fill the rest out for you. For example, we can make a correlation matrix using: Tri2M(c(1,0.5,1,0.3,0.2,1), lower.tri = FALSE, diag=TRUE) ## [,1] [,2] [,3] ## [1,] 1.0 0.5 0.3 ## [2,] 0.5 1.0 0.2 ## [3,] 0.3 0.2 1.0 Instead of specifying a variance-covariance matrix (vcov), we can also specify a variance-correlation matrix (variance on the diagonals and correlations on the off-diagonals), using vcorr squid_data &lt;- simulate_population( n=2000, response_name = &quot;body_mass&quot;, parameters=list( intercept=10, observation=list( names=c(&quot;temperature&quot;,&quot;rainfall&quot;, &quot;wind&quot;), mean = c(10,1,20), vcorr =matrix(c( 1, -0.2, 0.5, -0.2, 0.1, 0.3, 0.5, 0.3, 2 ), nrow=3 ,ncol=3,byrow=TRUE), beta =c(0.5,-3,0.4) ), residual=list( vcov=1 ) ) ) data &lt;- get_population_data(squid_data) cor(data[,c(&quot;temperature&quot;,&quot;rainfall&quot;, &quot;wind&quot;)]) ## temperature rainfall wind ## temperature 1.0000000 -0.2195430 0.5029664 ## rainfall -0.2195430 1.0000000 0.2634006 ## wind 0.5029664 0.2634006 1.0000000 Through simulating correlated predictors, we can also simulate more interesting phenomena. For example, we may want to simulate the effect of a correlated missing predictor. Here, rain and wind, but not temperature, affect adult body mass, but only temperature and rainfall are measured: squid_data &lt;- simulate_population( n=2000, response_name = &quot;body_mass&quot;, parameters=list( intercept=10, observation=list( names=c(&quot;temperature&quot;,&quot;rainfall&quot;, &quot;wind&quot;), mean = c(10,1 ,20), vcov =matrix(c( 1, 0, 1, 0,0.1,0, 1, 0, 2 ), nrow=3 ,ncol=3,byrow=TRUE), beta =c(0.5,-3,0.4) ), residual=list( vcov=1 ) ) ) data &lt;- get_population_data(squid_data) library(scales) par(mfrow=c(1,3)) plot(body_mass ~ temperature + rainfall + wind, data, pch=19, cex=0.5, col=alpha(1,0.5)) coef(lm(body_mass ~ temperature + rainfall, data)) ## (Intercept) temperature rainfall ## 14.2776190 0.8765735 -3.0422601 coef(lm(body_mass ~ temperature + rainfall + wind, data)) ## (Intercept) temperature rainfall wind ## 10.1035658 0.4516304 -3.0698659 0.4221429 We can also use this to induce measurement error in a predictor - we can simulate the true variable with a certain effect on the response, and another correlated variable - the measured variable - with no direct effect on the response. The correlation between these two variables represents the measurement error (the repeatability of the variable is the correlation squared). "],["1.3-interactions.html", "1.3 Interactions and non-linear effects", " 1.3 Interactions and non-linear effects 1.3.1 Interactions \\[ y_i = \\beta_0 + \\beta_1 x_{1i} + \\beta_2 x_{2i} + \\beta_3 x_{1i}x_{2i} + \\epsilon_i \\] We can specify the interaction between two predictors by adding an interactions list to the parameters list. Interactions can then be specified between two named variables using “:”. Interactions can be specified between two predictors at the same level, or at different hierarchical levels. squid_data &lt;- simulate_population( n=2000, response_name = &quot;body_mass&quot;, parameters=list( observation=list( names=c(&quot;temperature&quot;,&quot;rainfall&quot;), beta = c(0.5,0.3) ), residual=list( vcov=0.3 ), interactions=list( names=c(&quot;temperature:rainfall&quot;), beta = c(-0.1) ) ) ) data &lt;- get_population_data(squid_data) head(data) ## body_mass temperature rainfall residual temperature:rainfall squid_pop ## 1 -0.1950863 0.6545190 1.5577734 -0.8877186 1.0195922 1 ## 2 -0.8352969 -1.3405423 0.3989025 -0.3381711 -0.5347457 1 ## 3 -0.2615434 -1.2677241 -0.2484353 0.4783440 0.3149474 1 ## 4 0.8427175 0.8669511 0.1360867 0.3802140 0.1179805 1 ## 5 -0.8451921 -1.8557505 0.8777406 -0.3435258 -1.6288676 1 ## 6 0.7969244 -0.2192104 0.8250010 0.6409444 -0.1808488 1 coef(lm(body_mass ~ temperature * rainfall, data)) ## (Intercept) temperature rainfall ## 0.006055206 0.487910683 0.284464667 ## temperature:rainfall ## -0.084342268 1.3.2 Non-linear effects Polynomial (quadratic, cubic, etc) functions are essentially interactions with the same predictor. They can therefore be specified in the same way: squid_data &lt;- simulate_population( n=2000, response_name = &quot;body_mass&quot;, parameters=list( observation=list( names=c(&quot;temperature&quot;), beta = c(0.5) ), interactions=list( names=c(&quot;temperature:temperature&quot;), beta = c(-0.3) ), residual=list( vcov=0.3 ) ) ) data &lt;- get_population_data(squid_data) plot(body_mass ~ temperature, data, pch=19, cex=0.5, col=alpha(1,0.5)) coef(lm(body_mass ~ temperature + I(temperature^2), data)) ## (Intercept) temperature I(temperature^2) ## -0.003753765 0.510987516 -0.299719778 "],["1.4-transformations.html", "1.4 Transformations", " 1.4 Transformations We may want to simulate predictors that are not normally distributed. Although the underlying simulation procedure assumes multivariate normality, the predictors can be transformed, before they are multiplied by the beta values. To do this we can provide the transformation function to the functions option of a given parameter list, as a character vector. The given function needs to be a known function in R. The below code will exponentiate rainfall (using the exp function), before it is scaled by its beta (here 2). squid_data &lt;- simulate_population( n=2000, response_name = &quot;body_mass&quot;, parameters=list( observation=list( names=c(&quot;temperature&quot;,&quot;rainfall&quot;), functions=c(NA,&quot;exp&quot;), beta = c(0.5,0.3) ), residual=list( vcov=0.3 ) ) ) data &lt;- get_population_data(squid_data) head(data) ## body_mass temperature rainfall residual squid_pop ## 1 -0.4802574 -1.7993007 1.1968797 0.06032903 1 ## 2 1.3707870 1.4074719 0.7272089 0.44888842 1 ## 3 0.7889858 -0.2554504 0.4193276 0.79091279 1 ## 4 -0.1540081 -1.3475335 2.4882118 -0.22670489 1 ## 5 0.2024938 2.3573010 0.6904820 -1.18330134 1 ## 6 0.7422072 -0.1211901 2.0345061 0.19245041 1 hist(data$rainfall, xlab=&quot;Rainfall&quot;,main=&quot;&quot;, breaks=100) If a covariance between variables is specified, this covariance is on the untransformed (Gaussian) scale (as the variables are simulated as multivariate normal), NOT on the transformed scale, so care should be taken with this. For example: squid_data &lt;- simulate_population( n=2000, response_name = &quot;body_mass&quot;, parameters=list( observation=list( names=c(&quot;temperature&quot;,&quot;rainfall&quot;), vcov=matrix(c(1,0.7,0.7,1), nrow=2,byrow=TRUE), functions=c(NA,&quot;exp&quot;), beta = c(0.5,0.3) ), residual=list( vcov=0.3 ) ) ) data &lt;- get_population_data(squid_data) cov(data$temperature,data$rainfall) ## [1] 1.15377 cov(data$temperature,log(data$rainfall)) ## [1] 0.7097114 The simulated covariance can be recovered on the back-transformed predictor. The simulated_variance() function will also no longer be accurate, as the calculations are based on variables on the untransformed scale. "],["1.5-knownpreds.html", "1.5 Known Predictors", " 1.5 Known Predictors We might want to use existing predictors, rather than simulated ones, in our simulations. This has the advantage that any quirks of existing data (like a strange distribution) can be maintained. These predictors can be fed into the simulate_population() function, using the known_predictors argument. This argument takes a list, with one item, called predictors, a matrix or dataframe of predictors (the column names of which are used as variable names), and one item called beta, a vector with the beta values for the respective predictors. Importantly, the predictors have to be the same length as number of observations in the simulated data, and the betas have to be in the same order as the predictors. We can demonstrate this using the blue tit data set that comes with the MCMCglmm package. library(MCMCglmm) data(BTdata) head(BTdata) ## tarsus back animal dam fosternest hatchdate sex ## 1 -1.89229718 1.1464212 R187142 R187557 F2102 -0.6874021 Fem ## 2 1.13610981 -0.7596521 R187154 R187559 F1902 -0.6874021 Male ## 3 0.98468946 0.1449373 R187341 R187568 A602 -0.4279814 Male ## 4 0.37900806 0.2555847 R046169 R187518 A1302 -1.4656641 Male ## 5 -0.07525299 -0.3006992 R046161 R187528 A2602 -1.4656641 Fem ## 6 -1.13519543 1.5577219 R187409 R187945 C2302 0.3502805 Fem We can see that in this dataset there are several continuous predictors. Here we will use “hatchdate” and “tarsus”. squid_data &lt;- simulate_population( n = nrow(BTdata), response_name = &quot;body_mass&quot;, parameters = list( observation =list( names = c(&quot;temperature&quot;,&quot;rainfall&quot;), beta = c(0.5,0.3) ), residual = list( vcov = 0.3 ) ), known_predictors = list( predictors = BTdata[,c(&quot;hatchdate&quot;,&quot;tarsus&quot;)], beta = c(1,2)) ) data &lt;- get_population_data(squid_data) head(data) ## body_mass temperature rainfall residual hatchdate tarsus squid_pop ## 1 -4.996900 -0.7657209 1.28487082 -0.5275048 -0.6874021 -1.89229718 1 ## 2 1.471921 -0.9411953 0.79162697 0.1202132 -0.6874021 1.13610981 1 ## 3 1.452619 -0.8870048 0.05252918 0.3389656 -0.4279814 0.98468946 1 ## 4 -1.154444 0.5958834 -0.90299287 -0.4738395 -1.4656641 0.37900806 1 ## 5 -1.304388 1.7752999 0.34752697 -0.6801262 -1.4656641 -0.07525299 1 ## 6 -1.168326 0.2084304 1.99982911 0.0476203 0.3502805 -1.13519543 1 plot(body_mass~hatchdate,data) "],["1.6-nonGaussian.html", "1.6 Non-Gaussian phenotypes", " 1.6 Non-Gaussian phenotypes To simulate non-Gaussian data, we can specify a link function and a family as arguments to simulate_population(). Underneath the predictors are being simulated as multivariate normal (on the latent scale), and then the resulting phenotype is transformed (onto the expected scale) and then binomial or Poisson sampling is applied (the observed scale). Here is an example to simulate Poisson distributed data: \\[ y_i \\sim Poisson(\\lambda_i) \\] \\[ \\lambda_i = exp( \\beta_0 + \\boldsymbol{x}_{i} \\boldsymbol{\\beta} + \\epsilon_i ) \\] \\[ \\boldsymbol{x}_i \\sim \\mathcal{N}(\\boldsymbol{\\mu}_x, \\Sigma_x) \\] \\[ \\epsilon_i \\sim \\mathcal{N}(0,\\sigma^2_\\epsilon) \\] The only change in the code that is needed is the addition of the link and family arguments. squid_data &lt;- simulate_population( parameters = list( intercept = 1.75, observation = list( names = c(&quot;temperature&quot;,&quot;rainfall&quot;), beta = c(0.2,0.1) ), residual = list( vcov = 0.2 ) ), n = 2000, family = &quot;poisson&quot;, link = &quot;log&quot; ) data &lt;- get_population_data(squid_data) head(data) ## y temperature rainfall residual squid_pop ## 1 7 1.3004885 0.7155515 0.06216738 1 ## 2 6 1.9101220 1.3150074 -0.86303661 1 ## 3 7 1.9870723 1.0214374 -0.28948062 1 ## 4 2 0.3030570 -0.9352512 -0.75659522 1 ## 5 11 0.6905079 0.3606059 0.23477646 1 ## 6 22 1.6268158 -0.5810690 0.70292633 1 plot(table(data$y), ylab=&quot;Frequency&quot;, xlab=&quot;z&quot;) glm(y ~ temperature + rainfall, data, family=&quot;poisson&quot;) ## ## Call: glm(formula = y ~ temperature + rainfall, family = &quot;poisson&quot;, ## data = data) ## ## Coefficients: ## (Intercept) temperature rainfall ## 1.83996 0.17567 0.09701 ## ## Degrees of Freedom: 1999 Total (i.e. Null); 1997 Residual ## Null Deviance: 4808 ## Residual Deviance: 4290 AIC: 11320 Available families are ‘gaussian’, ‘poisson’ or ‘binomial’ and link functions ‘identity’, ‘log’, ‘inverse’, ‘sqrt’, ‘logit’, ‘probit’ and ‘cloglog’. 1.6.1 Transforming across scales It can be difficult to simulate data with a certain mean and variance on the ‘observed’ scale when using parameters on the ‘latent’ scale. {squidSim} provides two functions lat2exp() and exp2lat() that help do with the log transformation. lat2exp() transforms means and (co)variances from the latent (normal) scale to the expected (log-normal) scale, whilst exp2lat() does the reverse. Let us take an example. We want to simulate some count data that has a mean of 6 and variance 15. In a Poisson distribution, the mean is equal to the variance. This means that a variance of 6 will be added on to the expected scale variation through the stochastic Poisson sampling process. This means that we want to simulate data on the expected scale with a variance of 9. We can use the exp2lat() function to work out the mean and variance on the latent scale that will give us what we want on the expected scale. latent_params &lt;- exp2lat(mean=6, cov=9) latent_params ## $mean ## [1] 1.680188 ## ## $cov ## [,1] ## [1,] 0.2231436 This gives us a list of parameters with which we can simulate: squid_data &lt;- simulate_population( parameters = list( intercept = latent_params[[&quot;mean&quot;]], residual = list( vcov = latent_params[[&quot;cov&quot;]] ) ), n = 2000, family = &quot;poisson&quot;, link = &quot;log&quot; ) data &lt;- get_population_data(squid_data) mean(data$y) ## [1] 5.9065 var(data$y) ## [1] 15.18635 As you can see, we retrieve very similar values to those we were after. We can do with with other transformation. Another one with a simple transformation across scales is the probit. The probit transformation is simply the cumulative distribution function of a normal distribution, and so we can use the functions pnorm() and qnorm() to transform between latent and expected. "],["1.7-modeleq.html", "1.7 Model equations", " 1.7 Model equations In all the examples so far, the predictors are simulated, multiplied by their respective beta value, and then added together. When simulating more complex models, we may want to prevent some of this behaviour or add in additional parameters, interactions or general complexity. To introduce this increased complexity, we can specify a model formula. This explicitly tells simulate_population() how to put the simulated predictors together to form the response variable. We can first demonstrate this with a simple linear model. squid_data &lt;- simulate_population( parameters=list( observation= list( names = c(&quot;temperature&quot;, &quot;rainfall&quot;), beta =c(0.5,0.3) ), residual = list( names=&quot;residual&quot;, vcov=1 ) ), n=2000, model = &quot;y = temperature + rainfall + residual&quot; ) data &lt;- get_population_data(squid_data) coef(lm(y ~ temperature + rainfall, data)) ## (Intercept) temperature rainfall ## 0.01644183 0.52629681 0.29528224 In the formula, we write out how the variables are added up. Everything that you want exported needs to be defined and named (e.g. y=...). By default, all predictors are multiplied by their respective beta values before this happens. Sometimes it is useful to prevent this multiplication (e.g. multiply two traits together without them being multiplied by their respective beta). We can do this by using I(). squid_data &lt;- simulate_population( parameters=list( observation= list( names = c(&quot;temperature&quot;, &quot;rainfall&quot;), beta =c(0.5,0.3) ), residual = list( names=&quot;residual&quot;, vcov=1 ) ), n=2000, model = &quot;y = temperature + I(rainfall) + residual&quot; ) data &lt;- get_population_data(squid_data) coef(lm(y ~ temperature + rainfall, data)) ## (Intercept) temperature rainfall ## 0.02091335 0.52161524 1.00733900 We can also add extra parameters to the parameter list, which we can call from within the function. In combination with I() we can then customise the model formula a bit squid_data &lt;- simulate_population( parameters=list( observation= list( names = c(&quot;temperature&quot;, &quot;rainfall&quot;), beta =c(0.5,0.3), extra_beta = 0.1 ), residual = list( names=&quot;residual&quot;, vcov=1 ) ), n=2000, model = &quot;y = temperature + extra_beta*I(rainfall) + residual&quot; ) data &lt;- get_population_data(squid_data) coef(lm(y ~ temperature + rainfall, data)) ## (Intercept) temperature rainfall ## 0.02424607 0.47309430 0.08440587 Finally, we can use [] to index the levels of the random effects within the formula.. An example of this is given Section 4.4, along with use of the index_link argument. "],["1.8-npop.html", "1.8 Simulating multiple populations", " 1.8 Simulating multiple populations We can use the simulate_population() function to generate multiple datasets (populations) form the same set of parameters (world). To do this we can specify the n_pop argument in simulate_population(). This defaults to 1. squid_data &lt;- simulate_population( n=2000, response_name = &quot;body_mass&quot;, parameters=list( intercept=10, observation=list( names=c(&quot;temperature&quot;,&quot;rainfall&quot;, &quot;wind&quot;), beta =c(0.5,-0.3,0.4) ), residual=list( vcov=0.8 ) ), n_pop=5 ) By default get_population_data returns a data.frame, where the squid_pop column indicates the population data &lt;- get_population_data(squid_data) head(data) ## body_mass temperature rainfall wind residual squid_pop ## 1 10.132368 -1.9546951 0.4197320 0.21029426 1.15151743 1 ## 2 8.687849 -0.9974609 -0.3074322 -0.99049972 -0.50945076 1 ## 3 9.531882 0.5667092 0.1024663 -0.01125458 -0.71623081 1 ## 4 10.089348 -0.2627402 1.8010146 -0.71568383 1.04729598 1 ## 5 11.162227 -0.4583614 -1.6298772 -0.61950140 1.15024515 1 ## 6 10.154952 0.4401542 0.3017782 0.22296725 -0.06377881 1 tail(data) ## body_mass temperature rainfall wind residual squid_pop ## 9995 10.782432 1.05603425 -0.8132784 1.12810452 -0.4408101 5 ## 9996 10.458162 0.04709716 -0.3317510 -0.30729659 0.4580066 5 ## 9997 12.266405 2.09337257 0.6128256 0.27880803 1.2920434 5 ## 9998 8.853503 1.31778772 2.3277415 -0.55672678 -0.8843778 5 ## 9999 8.352746 -1.79613660 -0.7984681 -0.35913346 -0.8450724 5 ## 10000 10.080702 -2.51007818 -0.4660681 -0.04906956 1.2155489 5 It can also be output as a list, which might be more useful for processing many iterations of a simulation. data &lt;- get_population_data(squid_data, list=TRUE) length(data) ## [1] 5 "],["1.9-parameter-list-summary.html", "1.9 Parameter list summary", " 1.9 Parameter list summary The parameters list contains one (or more) list for each hierarchical level that you want to simulate at. A residual list is always needed, specifying variances/covariances for the residual. Additionally, the parameter list can also be provided with an intercept vector and interactions list. The simplest parameter list will look something like this: parameters=list( residual=list( vcov=... ) ) We can add more complexity by adding an intercept (if not specified, is assumed to be 0): parameters=list( intercept=c(...), residual=list( vcov=... ) ) and then simulate variables that vary at the observation level: parameters=list( intercept=c(...), observation=list( beta = ... ), residual=list( vcov = ... ) ) as well as variables that vary at the other levels, for example at the level of the individual: parameters=list( intercept=c(...), individual=list( names = c(...), beta = ... ), observation=list( names = c(...), beta = ... ), residual=list( vcov = ... ) ) Finally we can add in interactions: parameters=list( intercept=c(...), individual=list( names = c(...), beta = ... ), observation=list( names = c(...), beta = ... ), interactions=list( names = c(...), beta = ... ), residual=list( vcov = ... ) ) For each item in the parameter list (excluding intercept, interactions, and residual), the following can be specified: names Vector containing the names of predictors from this list that will be output. This doesn’t not have to be specified, unless the predictors at this level are included in interactions. By default, the names will be the name of the list (e.g. ‘individual’ in the example above), appended with _effect and a sequential number if there are multiple predictors. group Character string relates the level of variation back to the data_structure. Does not have to be specified and by default is the name of the list. mean Vector of means for the predictor variables. Defaults to 0. vcov Either a vector of variances, or a variance-covariance matrix, for the predictor variables. Defaults to identity matrix. vcorr Variance-correlation matrix, can be specified instead of vcov (it is ignored if both are specified). beta Vector (or matrix with multiple responses) of effect sizes/slopes. Defaults to 1. fixed Logical, indicating whether the effects for the levels are fixed or to be simulated. If TRUE, beta represents the fixed effects. Defaults to FALSE. covariate Logical, indicating whether the indexes in the data structure are to be used as a continuous variable rather than simulating one. Defaults to FALSE. functions Vector - transformation to be applied to the response variable. Defaults to ‘identity’. "],["2-hierarchical.html", "2 Hierarchical structure", " 2 Hierarchical structure There are two parts to simulating hierarchical data. First you need to have a hierarchical data structure and second you need parameters at each of the different hierarchical levels. The data structure is essentially a data.frame (or matrix), with all the grouping factors and their levels, as we would see in a typical dataset. Lets take the blue tit dataset we explored earlier: data(BTdata) head(BTdata) ## tarsus back animal dam fosternest hatchdate sex ## 1 -1.89229718 1.1464212 R187142 R187557 F2102 -0.6874021 Fem ## 2 1.13610981 -0.7596521 R187154 R187559 F1902 -0.6874021 Male ## 3 0.98468946 0.1449373 R187341 R187568 A602 -0.4279814 Male ## 4 0.37900806 0.2555847 R046169 R187518 A1302 -1.4656641 Male ## 5 -0.07525299 -0.3006992 R046161 R187528 A2602 -1.4656641 Fem ## 6 -1.13519543 1.5577219 R187409 R187945 C2302 0.3502805 Fem Here animal, dam, fosternest and sex make up the data structure. In this Section, we will first demonstrate how to make a simple hierarchical structure using the make_structure function. simulate_population also allows pre-existing data structures to be incorporated into simulations. The remaining part of the section details how to simulate hierarchical data once you have a hierarchical data structure. "],["2.1-makestr.html", "2.1 Making a hierarchical structure", " 2.1 Making a hierarchical structure We can use the make_structure function to create nested and crossed hierarchical data structures. The make_structure function only produces balanced data structures, but these can be made unbalanced by sampling, which is outlined in Section 7 2.1.1 Single Factor Simplest structure - one grouping factor with multiple observations. Here we create a structure with 2 repeated observations of 5 individuals (small number are used here simply for illustration purposes). The structure contains the name of the grouping factors and their sample sizes, and repeat_obs is the number of repeated observations. make_structure(structure=&quot;individual(5)&quot;, repeat_obs=2) ## individual ## 1 1 ## 2 1 ## 3 2 ## 4 2 ## 5 3 ## 6 3 ## 7 4 ## 8 4 ## 9 5 ## 10 5 2.1.2 Nested factors If we want to have nested factors, so different hierarchical groups, where levels of one group only exist in one higher group then we can use the / symbol in the structure argument. For example, here we have 2 sexes, each with 5 individuals, with 2 repeated measurements each. make_structure(structure=&quot;sex(2)/individual(5)&quot;, repeat_obs=2) ## sex individual ## 1 1 1 ## 2 1 1 ## 3 1 2 ## 4 1 2 ## 5 1 3 ## 6 1 3 ## 7 1 4 ## 8 1 4 ## 9 1 5 ## 10 1 5 ## 11 2 6 ## 12 2 6 ## 13 2 7 ## 14 2 7 ## 15 2 8 ## 16 2 8 ## 17 2 9 ## 18 2 9 ## 19 2 10 ## 20 2 10 Note that in the nesting, the sample size for the lower group now represents the number within each level of the higher, rather than the total sample size, so overall there is 10 individuals. We can nest as much as we want: make_structure(structure=&quot;species(2)/population(2)/individual(2)&quot;, repeat_obs=2) ## species population individual ## 1 1 1 1 ## 2 1 1 1 ## 3 1 1 2 ## 4 1 1 2 ## 5 1 2 3 ## 6 1 2 3 ## 7 1 2 4 ## 8 1 2 4 ## 9 2 3 5 ## 10 2 3 5 ## 11 2 3 6 ## 12 2 3 6 ## 13 2 4 7 ## 14 2 4 7 ## 15 2 4 8 ## 16 2 4 8 2.1.3 Crossed factors We can create completely crossed factors - every combination of levels exists - using the + symbol in the structure argument make_structure(structure=&quot;treatment(2) + individual(5)&quot;, repeat_obs=1) ## treatment individual ## 1 1 1 ## 2 1 2 ## 3 1 3 ## 4 1 4 ## 5 1 5 ## 6 2 1 ## 7 2 2 ## 8 2 3 ## 9 2 4 ## 10 2 5 We can combine crossed and nested structures: make_structure(structure=&quot;treatment(2) + sex(2)/individual(5)&quot;, repeat_obs=1) ## treatment sex individual ## 1 1 1 1 ## 2 1 1 2 ## 3 1 1 3 ## 4 1 1 4 ## 5 1 1 5 ## 6 1 2 6 ## 7 1 2 7 ## 8 1 2 8 ## 9 1 2 9 ## 10 1 2 10 ## 11 2 1 1 ## 12 2 1 2 ## 13 2 1 3 ## 14 2 1 4 ## 15 2 1 5 ## 16 2 2 6 ## 17 2 2 7 ## 18 2 2 8 ## 19 2 2 9 ## 20 2 2 10 We can also output the crossed and nested using : make_structure(structure=&quot;treatment(2) + individual(5) + treatment:individual&quot;, repeat_obs=1) ## treatment individual treatment_individual ## 1 1 1 1 ## 2 1 2 2 ## 3 1 3 3 ## 4 1 4 4 ## 5 1 5 5 ## 6 2 1 6 ## 7 2 2 7 ## 8 2 3 8 ## 9 2 4 9 ## 10 2 5 10 2.1.4 Temporal structure ds &lt;- make_structure(structure=&quot;year(2)/month(12)/day(30)&quot;, repeat_obs=1) head(ds) ## year month day ## 1 1 1 1 ## 2 1 1 2 ## 3 1 1 3 ## 4 1 1 4 ## 5 1 1 5 ## 6 1 1 6 ds &lt;- make_structure(structure=&quot;year(2) + month(12) + day(30) + year:month:day&quot;, repeat_obs=1) head(ds) ## year month day year_month_day ## 1 1 1 1 1 ## 2 1 1 2 2 ## 3 1 1 3 3 ## 4 1 1 4 4 ## 5 1 1 5 5 ## 6 1 1 6 6 2.1.5 Naming factor levels Rather than just outputting 1 - N levels for the level names of each factor, we might want to assign names. This can be done for all or some of the grouping factors, using the level_names argument. We can input a list, with an item in the list for each grouping factor we want to assign names, and then a vector of their names, which is the same length of the number of levels in that grouping factor. For example, below we just assign names to the two sexes: make_structure(structure=&quot;sex(2)/individual(5)&quot;, repeat_obs=2, level_names=list(sex=c(&quot;female&quot;,&quot;male&quot;))) ## sex individual ## 1 female 1 ## 2 female 1 ## 3 female 2 ## 4 female 2 ## 5 female 3 ## 6 female 3 ## 7 female 4 ## 8 female 4 ## 9 female 5 ## 10 female 5 ## 11 male 6 ## 12 male 6 ## 13 male 7 ## 14 male 7 ## 15 male 8 ## 16 male 8 ## 17 male 9 ## 18 male 9 ## 19 male 10 ## 20 male 10 And then to the individuals and the sexes make_structure(structure=&quot;sex(2)/individual(5)&quot;, repeat_obs=2, level_names=list(sex=c(&quot;female&quot;,&quot;male&quot;),individual=paste0(&quot;ind_&quot;,1:10))) ## sex individual ## 1 female ind_1 ## 2 female ind_1 ## 3 female ind_2 ## 4 female ind_2 ## 5 female ind_3 ## 6 female ind_3 ## 7 female ind_4 ## 8 female ind_4 ## 9 female ind_5 ## 10 female ind_5 ## 11 male ind_6 ## 12 male ind_6 ## 13 male ind_7 ## 14 male ind_7 ## 15 male ind_8 ## 16 male ind_8 ## 17 male ind_9 ## 18 male ind_9 ## 19 male ind_10 ## 20 male ind_10 "],["2.2-factors.html", "2.2 Factors", " 2.2 Factors In the first sections, we just simulated continuous predictors, varying at the level of the observation. However, we may want to simulate factors with known or fixed effects (i.e. not variables drawn randomly from a particular distribution) at different levels, such as sex or treatment effects. The first thing we want to do is specify a simple data structure, for example 100 observations for each of two sexes: ds &lt;- make_structure(structure=&quot;sex(2)&quot;, repeat_obs=100, level_names=list(sex=c(&quot;female&quot;,&quot;male&quot;))) Then we feed this data structure into the simulate_population() function using the data_structure argument. Note that we no longer need to specify the sample size (n), as this is taken from the number of rows in the data_structure. squid_data &lt;- simulate_population( data_structure = ds, parameters = ... ) In order to tell the parameter list we have effects that vary at different hierarchical levels, we can create additional slots in the parameter list for the grouping factors, so now it will look something like: squid_data &lt;- simulate_population( data_structure = ds, parameters = list( intercept = ..., sex = list( ... ), observation = list( ... ), residual = list( ... ) ) ) The names in the parameter list that relate to the different grouping factors either need to match the name in the data structure exactly (as above) or a ‘group’ argument needs to be given e.g. squid_data &lt;- simulate_population( data_structure = ds, parameters = list( intercept = ..., anything = list( group=&quot;sex,&quot; ... ), observation = list( ... ), residual = list( ... ) ) ) We then need to tell the parameters list that we have fixed effects for this grouping factor, in other words we know the difference in body size between the sexes is 0.5, for example. To do this we specify fixed = TRUE. squid_data &lt;- simulate_population( data_structure = ds, parameters = list( intercept = ..., sex = list( fixed=TRUE, ... ), observation = list( ... ), residual = list( ... ) ) ) We can then give a beta for all the different levels of that group. Note that there are two ways to specify this, as there also is in linear models in R. First, we can specify an intercept, and contrasts, equivalent to the output of lm(body_mass~sex), which involves specifying the beta for the first level as 0 to make it the baseline level (or any other level that you would like to be the baseline). Note that, as of version 0.2.4, if the levels for this grouping factor in the data structure have names (in this case “male” and “female”), then the same names have to be specified in the parameter list. squid_data &lt;- simulate_population( data_structure = ds, parameters = list( intercept= 10, sex=list( fixed=TRUE, beta=c(0,0.5), names = c(&quot;female&quot;,&quot;male&quot;) ), residual = list( vcov = 0.5 ) ) ) data &lt;- get_population_data(squid_data) boxplot( y ~ factor(sex), data) lm( y ~ factor(sex), data) ## ## Call: ## lm(formula = y ~ factor(sex), data = data) ## ## Coefficients: ## (Intercept) factor(sex)male ## 10.176 0.377 Alternately, we can specify no intercept (which defaults to 0), and the means for the two levels as betas (equivalent to lm(body_mass~0+sex)): squid_data &lt;- simulate_population( data_structure = ds, parameters = list( sex=list( fixed=TRUE, beta=c(10,10.5), names = c(&quot;female&quot;,&quot;male&quot;) ), residual = list( vcov = 0.5 ) ) ) data &lt;- get_population_data(squid_data) boxplot( y ~ factor(sex), data) lm( y ~ factor(sex), data) ## ## Call: ## lm(formula = y ~ factor(sex), data = data) ## ## Coefficients: ## (Intercept) factor(sex)male ## 10.132 0.409 lm( y ~ 0+factor(sex), data) ## ## Call: ## lm(formula = y ~ 0 + factor(sex), data = data) ## ## Coefficients: ## factor(sex)female factor(sex)male ## 10.13 10.54 We would recommend the former method, as this makes things clearer if other factors are simulated. 2.2.1 Fixed Factor Interactions We might want to simulate an interaction between a continuous predictor and a factor, for example the effect of the environment varying between two sexes. Specifying this using simulate_population() is similar to interactions between two continuous predictors that we have previously encountered (Section 1.3). In the interaction part of the parameter list, we now specify the contrasts between the slopes for environment, using the names that we have assigned the different levels. In the simulation below, males are larger, and have a larger environment slope: squid_data &lt;- simulate_population( data_structure = make_structure(structure = &quot;sex(2)&quot;, repeat_obs=1000), parameters = list( intercept=10, sex=list( fixed=TRUE, names=c(&quot;female&quot;,&quot;male&quot;), beta=c(0,0.5) ), observation= list( names = c(&quot;environment&quot;), beta =c(0.2) ), interactions = list( names=c(&quot;environment:male&quot;), beta = 0.4 ), residual = list( names=&quot;residual&quot;, vcov = 0.1 ) ) ) data &lt;- get_population_data(squid_data) head(data) ## y female male environment residual environment:male sex squid_pop ## 1 9.750474 1 0 -1.25796735 0.002067288 0 1 1 ## 2 10.456740 1 0 -0.92214063 0.641167781 0 1 1 ## 3 10.327966 1 0 0.67783250 0.192399695 0 1 1 ## 4 9.976236 1 0 0.71095086 -0.165954375 0 1 1 ## 5 9.984801 1 0 -0.08647446 0.002095792 0 1 1 ## 6 10.295880 1 0 2.87982801 -0.280085298 0 1 1 plot(y~environment,data, pch=19, col=scales::alpha(c(1,2),0.5)[factor(data$sex)]) lm( y ~ 0 + factor(sex)*environment, data) ## ## Call: ## lm(formula = y ~ 0 + factor(sex) * environment, data = data) ## ## Coefficients: ## factor(sex)1 factor(sex)2 environment ## 10.0031 10.4872 0.2023 ## factor(sex)2:environment ## 0.3867 "],["2.3-simulating-predictors-at-different-hierarchical-levels.html", "2.3 Simulating predictors at different hierarchical levels", " 2.3 Simulating predictors at different hierarchical levels As well as simulating continuous predictors at the level of the observation, we can also simulate predictors at different hierarchical levels. Let’s take the example of a situation where we have repeated measures of individuals. The individuals have traits that are consistently expressed, whilst the environment varies between observations. We can describe variation at these different hierarchical levels as: \\[ y_{ij} = \\beta_0 + \\boldsymbol{x}_{i} \\boldsymbol{\\beta}_x + \\boldsymbol{u}_j \\boldsymbol{\\beta}_u + \\epsilon_{ij} \\] \\[ \\boldsymbol{x}_i \\sim \\mathcal{N}(\\boldsymbol{\\mu}_x, \\Sigma_x) \\] \\[ \\boldsymbol{u}_j \\sim \\mathcal{N}(\\boldsymbol{\\mu}_u, \\Sigma_u) \\] \\[ \\epsilon_i \\sim \\mathcal{N}(0,\\sigma^2_\\epsilon) \\] where \\(U\\) is a matrix of predictors that vary at the individual level (denoted by the subscript \\(j\\)), and \\(X\\) is a matrix of predictors at the observation level (denoted by the index \\(i\\)). In order to simulate from this model, we need a data structure and parameters for each of these levels. To do this, we can either specify a data structure generated using make_structure (outlined previously in Section 2.1), or a pre-existing data structure, to the simulate_population function. We then add an item to the parameter list, the name of which matches on of the grouping factors in the data structure, and specify the parameters for predictors that vary at that level in the same way as outlined in the previous section (1). This is similar to the fixed factors above, but we are now assuming that the variable is drawn randomly from a distribution, rather than the effects at each level being fixed. Lets imagine that we simulate behaviour, that is a functions of an individual’s size and physiology, and also varies in response to the environment, here temperature and rainfall: squid_data &lt;- simulate_population( data_structure = make_structure(structure = &quot;individual(500)&quot;, repeat_obs=2), parameters = list( individual = list( names = c(&quot;size&quot;,&quot;physiology&quot;), beta = c(0.1,0.2) ), observation = list( names=c(&quot;temperature&quot;,&quot;rainfall&quot;), beta = c(0.2,-0.1) ), residual = list( vcov = 0.5 ) ), response_names=&quot;behaviour&quot; ) data &lt;- get_population_data(squid_data) coef(lm(behaviour ~ size + physiology + temperature + rainfall , data)) ## (Intercept) size physiology temperature rainfall ## -0.03402370 0.07313193 0.17416616 0.24872731 -0.11561841 Here, we have simulated 4 predictors, ‘size’ and ‘physiology’ that vary at the level of the individual, and ‘temperature’ and ‘rainfall’ that vary at the level of the observation. To keep things simple, we will simulate them all as unit normal variables (mean=0 and variance=1). Note, the names of the different grouping factors in the parameter list (here ‘individual’) needs to exactly match those in the data structure. The order does not, however, have to be the same. There are circumstances in which we may want to simulate two sets of effects at the same hierarchical level (for example see permanent environment effects in Section 4.1), in this case we can call them different things in the parameter list, but link them back to the grouping factor, by providing a group name. For example the following will produce the same simulation as above: squid_data &lt;- simulate_population( data_structure = make_structure(structure = &quot;individual(500)&quot;, repeat_obs=2), parameters = list( ind1 = list( group=&quot;individual&quot;, names = c(&quot;size&quot;), beta = c(0.1) ), ind2 = list( group=&quot;individual&quot;, names = c(&quot;physiology&quot;), beta = c(0.2) ), observation = list( names=c(&quot;temperature&quot;,&quot;rainfall&quot;), beta = c(0.2,-0.1) ), residual = list( vcov = 0.5 ) ), response_names=&quot;behaviour&quot; ) It is also worth noting that predictors do not have to be simulated for every grouping factor in the data structure - in this way no variation at that level can be simulated. 2.3.1 Simulating ‘random’ effects In essence, random effects (random intercepts) represent an unobserved/latent predictor (or group of predictors), which varies at a given hierarchical level. In a mixed effect model, the effect at each level of the grouping factor is unknown, and estimated by the model (and assumed to come from a normal distribution). When simulating this, however, we can simply simulate an additional predictor at a particular hierarchical level (\\(z\\)) with mean 0 and a given variance (\\(\\sigma^2_z\\)). \\[ y_{ij} = \\beta_0 + u_j + \\epsilon_{ij} \\] \\[ u_j \\sim \\mathcal{N}(0,\\sigma^2_u) \\] \\[ \\epsilon_i \\sim \\mathcal{N}(0,\\sigma^2_\\epsilon) \\] For example, we can simulate some among-individual variation as follows: squid_data &lt;- simulate_population( data_structure = make_structure(structure = &quot;individual(500)&quot;, repeat_obs=2), parameters = list( individual = list( vcov = 0.5 ), residual = list( vcov = 0.5 ) ) ) data &lt;- get_population_data(squid_data) head(data) ## y individual_effect residual individual squid_pop ## 1 0.602356146 0.1594673 0.4428889 1 1 ## 2 1.204485552 0.1594673 1.0450183 1 1 ## 3 -0.681867088 -0.3816181 -0.3002490 2 1 ## 4 -1.436016418 -0.3816181 -1.0543983 2 1 ## 5 0.006081218 0.7306521 -0.7245709 3 1 ## 6 0.177797638 0.7306521 -0.5528544 3 1 library(lme4) short_summary &lt;- function(x) print(summary(x), correlation=FALSE, show.resids=FALSE, ranef.comp = c(&quot;Variance&quot;)) short_summary(lmer(y ~ 1 + (1|individual), data)) ## Linear mixed model fit by REML [&#39;lmerMod&#39;] ## Formula: y ~ 1 + (1 | individual) ## Data: data ## ## REML criterion at convergence: 2694 ## ## Random effects: ## Groups Name Variance ## individual (Intercept) 0.4741 ## Residual 0.5103 ## Number of obs: 1000, groups: individual, 500 ## ## Fixed effects: ## Estimate Std. Error t value ## (Intercept) 0.03428 0.03819 0.898 Note that here we haven’t specified any variable names. In this case the simulated predictors are named by the grouping factors (e.g. individual_effect). 2.3.2 Incorporating existing data structures We could also use an existing data structure, taking the grouping factors and levels from an existing dataset and input them to simulate_population. To demonstrate this, we can use the blue tit dataset provided with the MCMCglmm package. This is a dataset with some continuous variables (tarsus, back (coloration) and hatchdate), and some grouping factors (animal, dam, fosternest and sex), the latter providing a data structure from which to simulate. library(MCMCglmm) data(BTdata) head(BTdata) ## tarsus back animal dam fosternest hatchdate sex ## 1 -1.89229718 1.1464212 R187142 R187557 F2102 -0.6874021 Fem ## 2 1.13610981 -0.7596521 R187154 R187559 F1902 -0.6874021 Male ## 3 0.98468946 0.1449373 R187341 R187568 A602 -0.4279814 Male ## 4 0.37900806 0.2555847 R046169 R187518 A1302 -1.4656641 Male ## 5 -0.07525299 -0.3006992 R046161 R187528 A2602 -1.4656641 Fem ## 6 -1.13519543 1.5577219 R187409 R187945 C2302 0.3502805 Fem squid_data &lt;- simulate_population( data_structure = BTdata[,c(&quot;dam&quot;,&quot;fosternest&quot;)], parameters = list( dam = list( vcov = 0.2 ), fosternest = list( vcov = 0.3 ), residual = list( vcov = 0.5 ) ) ) data &lt;- get_population_data(squid_data) head(data) ## y dam_effect fosternest_effect residual dam fosternest ## 1 0.3414224 0.0004465141 0.26993761 0.07103831 R187557 F2102 ## 2 0.4892094 0.0512931487 -0.13437510 0.57229137 R187559 F1902 ## 3 1.6103895 0.0428057278 0.69045892 0.87712480 R187568 A602 ## 4 -1.3354583 -0.2351044549 -0.61425069 -0.48610310 R187518 A1302 ## 5 -0.1467267 0.9155448975 -0.44713888 -0.61513276 R187528 A2602 ## 6 1.3456794 0.5799862495 0.02555989 0.74013326 R187945 C2302 ## squid_pop ## 1 1 ## 2 1 ## 3 1 ## 4 1 ## 5 1 ## 6 1 "],["2.4-randomslopes.html", "2.4 Random Regression", " 2.4 Random Regression Random regression (or a random intercepts and slopes model) essentially represents an interaction (or product) between predictors at different levels, with the random slopes being an unobserved, latent variable (\\(u_2\\)). \\[ y_{ij} = \\beta_0 + \\beta_1x_{i} + u_{1j} + u_{2j}x_{i} + \\epsilon_{ij} \\] \\[ x_i \\sim \\mathcal{N}(0,\\sigma^2_{x}) \\] \\[ \\boldsymbol{u}_i \\sim \\mathcal{N}(0, \\Sigma_u) \\] \\[ \\epsilon \\sim \\mathcal{N}(0,\\sigma^2_\\epsilon) \\] We can specify random slopes by simulating a slope variable at the individual level (ind_slope - \\(u_{2}\\)). We can specify the mean environmental effect the slope of the environmental variable (\\(beta_1\\)). \\(u_{2}\\) then represents the deviations from the mean slope (this is typically how it is modelled in a linear mixed effect model). Importantly the beta parameter associated with ind_slope is specified as 0 (there is no ‘main effect’ of the slopes, just the interaction), and the beta parameter associated with interaction is 1. squid_data &lt;- simulate_population( data_structure=make_structure(&quot;individual(300)&quot;,repeat_obs=10), parameters = list( individual = list( names = c(&quot;ind_int&quot;,&quot;ind_slope&quot;), beta = c(1,0), vcov = c(1,0.5) ), observation= list( names = c(&quot;environment&quot;), beta = c(0.2) ), residual = list( vcov = c(0.5) ), interactions = list( names = c(&quot;ind_slope:environment&quot;), beta = c(1) ) ) ) data &lt;- get_population_data(squid_data) short_summary(lmer(y ~ environment + (1+environment|individual),data)) ## Linear mixed model fit by REML [&#39;lmerMod&#39;] ## Formula: y ~ environment + (1 + environment | individual) ## Data: data ## ## REML criterion at convergence: 8075.9 ## ## Random effects: ## Groups Name Variance Cov ## individual (Intercept) 0.9964 ## environment 0.5520 0.04 ## Residual 0.5060 ## Number of obs: 3000, groups: individual, 300 ## ## Fixed effects: ## Estimate Std. Error t value ## (Intercept) -0.06715 0.05922 -1.134 ## environment 0.24393 0.04546 5.366 We can make the link between the code and the equation more explicit, by expanding out the equation: \\[ y_{ij} = \\beta_0 + \\beta_xx_{i} + \\boldsymbol{u}_j \\boldsymbol{\\beta}_u + \\beta_{ux}u_{2j}x_{i} + \\epsilon_{ij} \\] \\[ \\color{CornflowerBlue}{\\boldsymbol{\\beta_u} = \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix}} , \\color{orange}{\\beta_{ux}=1} \\] squid_data &lt;- simulate_population( data_structure=make_structure(&quot;individual(300)&quot;,repeat_obs=10), parameters = list( individual = list( names = c(&quot;ind_int&quot;,&quot;ind_slope&quot;), beta = c(1,0), vcov = c(1,0.5) ), observation= list( names = c(&quot;environment&quot;), beta = c(0.2) ), residual = list( vcov = c(0.5) ), interactions = list( names = c(&quot;ind_slope:environment&quot;), beta = c(1) ) ) ) Here we have specified no correlation between intercepts and slopes. To simulate a covariance/correlation between intercepts and slopes, we can simply give the vcov argument a covariance matrix, instead of two variances: squid_data &lt;- simulate_population( data_structure=make_structure(&quot;individual(300)&quot;,repeat_obs=10), parameters = list( individual = list( names = c(&quot;ind_int&quot;,&quot;ind_slope&quot;), beta = c(1,0), vcov = matrix(c(1,0.3,0.3,0.5),ncol=2,nrow=2,byrow=TRUE) ), observation= list( names = c(&quot;environment&quot;), beta = c(0.2) ), residual = list( vcov = c(0.5) ), interactions = list( names = c(&quot;ind_slope:environment&quot;), beta = c(1) ) ) ) data &lt;- get_population_data(squid_data) short_summary(lmer(y ~ environment + (1+environment|individual),data)) ## Linear mixed model fit by REML [&#39;lmerMod&#39;] ## Formula: y ~ environment + (1 + environment | individual) ## Data: data ## ## REML criterion at convergence: 8122.5 ## ## Random effects: ## Groups Name Variance Cov ## individual (Intercept) 1.1279 ## environment 0.4933 0.33 ## Residual 0.5244 ## Number of obs: 3000, groups: individual, 300 ## ## Fixed effects: ## Estimate Std. Error t value ## (Intercept) 0.009427 0.062869 0.150 ## environment 0.266923 0.043233 6.174 "],["2.5-BetweenWithin.html", "2.5 Among- and within-group effects", " 2.5 Among- and within-group effects We may want to simulate the case where a predictor variable varies both within and among groups - in other words it is repeatable at the group level. For example, if we are simulating body mass, we might expect that body mass is a function of an environmental variable, rainfall, and that differs systematically among individuals, as well as within, for example due to spatial variation in where individual lives. The simplest way of simulating this is as two rainfall variables, one at the level of the individual and one at the level of the observation, something like: squid_data &lt;- simulate_population( data_structure=make_structure(&quot;individual(100)&quot;, repeat_obs=5), parameters = list( individual=list( names=c(&quot;between_rainfall&quot;), ... ), observation=list( names=c(&quot;within_rainfall&quot;), ... ), residual=list( ... ) ) ) We can then specify the variation in rainfall within and between individuals, for example, if the repeatability of rainfall amongst individuals is 0.5, and the total variance in rainfall is 0.8, we would make the variance in rainfall 0.4 at each level: squid_data &lt;- simulate_population( data_structure=make_structure(&quot;individual(100)&quot;, repeat_obs=5), parameters = list( individual=list( names=c(&quot;between_rainfall&quot;), vcov=0.4, ... ), observation=list( names=c(&quot;within_rainfall&quot;), vcov=0.4, ... ), residual=list( 0.8 ) ) ) If we want the rainfall variable to have a mean that is not 0, we should specify this in only one place, as otherwise they will add up weirdly! squid_data &lt;- simulate_population( data_structure=make_structure(&quot;individual(100)&quot;, repeat_obs=5), parameters = list( individual=list( names=c(&quot;between_rainfall&quot;), vcov=0.4, ... ), observation=list( names=c(&quot;within_rainfall&quot;), vcov=0.4, mean=10 ), residual=list( 0.8 ) ) ) Now we want to add in some betas. If the effect of rainfall on body mass is causal, we would expect the beta to be the same at both levels - this results as a simple reorganisation of the model equation. We start with an effect of rainfall on body size \\[ y_i = \\beta_0 + \\beta_1 (x_{ij}) + \\epsilon_i \\] where \\(x_{ij}\\) is rainfall varying at levels \\(i\\) (observation) and \\(j\\) (individual). We can split rainfall up into within (\\(x_{1i}\\)) and between (\\(u_{1i}\\)) individual components: \\[ y_i = \\beta_0 + \\beta_1 (u_{j} + x_{i}) + \\epsilon_i \\] \\[ y_i = \\beta_0 + \\beta_1u_{j} + \\beta_{1}x_{i} + \\epsilon_i \\] you see that the coefficients should be the same. squid_data &lt;- simulate_population( data_structure=make_structure(&quot;individual(100)&quot;, repeat_obs=5), parameters = list( individual=list( names=c(&quot;between_env&quot;, &quot;ind_int&quot;), vcov=c(0.5,1), beta=c(-2,1) ), observation=list( names=c(&quot;within_env&quot;), vcov=c(0.5), beta=c(2) ), residual=list( vcov=1 ) ) ) data &lt;- get_population_data(squid_data) data$environment &lt;- data$between_env + data$within_env "],["3-multivariate.html", "3 Multi-response Models", " 3 Multi-response Models We can simulate multiple response variables, that covary at different hierarchical levels. For example, we might have two phenotypes, body mass and behaviour, that covary at the between individual and within individual (residual) levels. In the case of such a simple random effects model, we have a covariance matrix at each level: \\[ \\boldsymbol{y}_{ij} = \\boldsymbol{\\beta}_0 + \\boldsymbol{u}_j + \\boldsymbol{\\epsilon}_{ij} \\] \\[ \\boldsymbol{u}_i \\sim \\mathcal{N}(0, \\Sigma_u) \\] \\[ \\boldsymbol{\\epsilon}_{i} \\sim \\mathcal{N}(0, \\Sigma_{\\epsilon}) \\] \\[ \\Sigma_u = \\begin{bmatrix} \\sigma^2_{u_1} &amp; \\sigma_{u_1u_2} \\\\ \\sigma_{u_1u_2} &amp; \\sigma^2_{u_2} \\end{bmatrix} , \\Sigma_{\\epsilon} = \\begin{bmatrix} \\sigma^2_{\\epsilon_1} &amp; \\sigma_{\\epsilon_1\\epsilon_2} \\\\ \\sigma_{\\epsilon_1\\epsilon_2} &amp; \\sigma^2_{\\epsilon_2} \\end{bmatrix} \\] We can indicate that there are multiple phenotypes within the parameter list using the n_response argument. If we have \\(q\\) response variables, vcov now needs to either be a vector of length \\(q\\) (the variances, if we assume the covariances are 0) or a \\(q*q\\) covariance matrix. So below, we simulate 2 response variables, with a covariance between them at both individual and residual levels. squid_data &lt;- simulate_population( data_structure=make_structure(structure = &quot;individual(100)&quot;,repeat_obs=10), n_response = 2, parameters=list( individual = list( vcov = matrix(c(1,0.5,0.5,1),nrow=2,ncol=2,byrow=TRUE) ), residual = list( vcov = matrix(c(1,0.5,0.5,1),nrow = 2,ncol = 2,byrow=TRUE) ) ) ) We haven’t specified any names (of responses or predictors). By default, simulate_population() will add a number to the default name to indicate which reponse variable it refers to, so here we have y1 and y2 for the response variable, and individual_effect1 and individual_effect2 etc. data &lt;- get_population_data(squid_data) head(data) ## y1 y2 individual_effect1 individual_effect2 residual1 ## 1 1.1054644 1.4127080 2.480034 1.634281 -1.37456980 ## 2 4.1766734 0.8345915 2.480034 1.634281 1.69663917 ## 3 1.7790364 0.5872531 2.480034 1.634281 -0.70099782 ## 4 0.7353167 0.5515726 2.480034 1.634281 -1.74471750 ## 5 2.4911567 0.9464126 2.480034 1.634281 0.01112246 ## 6 5.1880032 3.3071899 2.480034 1.634281 2.70796900 ## residual2 individual squid_pop ## 1 -0.2215732 1 1 ## 2 -0.7996898 1 1 ## 3 -1.0470282 1 1 ## 4 -1.0827086 1 1 ## 5 -0.6878687 1 1 ## 6 1.6729086 1 1 We can name the response variables easily, by giving the response_name argument a vector of names squid_data &lt;- simulate_population( data_structure=make_structure(structure = &quot;individual(100)&quot;,repeat_obs=10), n_response = 2, response_name = c(&quot;body_mass&quot;,&quot;behaviour&quot;), parameters=list( individual = list( vcov = matrix(c(1,0.5,0.5,1),nrow=2,ncol=2,byrow=TRUE) ), residual = list( vcov = matrix(c(1,0.5,0.5,1),nrow = 2,ncol = 2,byrow=TRUE) ) ) ) data &lt;- get_population_data(squid_data) head(data) ## body_mass behaviour individual_effect1 individual_effect2 residual1 ## 1 -0.45333155 -2.3819621 -0.5478939 -0.09634067 0.09456232 ## 2 -0.43114173 -0.6964292 -0.5478939 -0.09634067 0.11675214 ## 3 -2.57715631 -0.9151838 -0.5478939 -0.09634067 -2.02926243 ## 4 -0.09299664 -0.1446033 -0.5478939 -0.09634067 0.45489723 ## 5 -0.92695565 1.2149131 -0.5478939 -0.09634067 -0.37906178 ## 6 -1.99656829 -0.6476084 -0.5478939 -0.09634067 -1.44867441 ## residual2 individual squid_pop ## 1 -2.28562139 1 1 ## 2 -0.60008852 1 1 ## 3 -0.81884311 1 1 ## 4 -0.04826266 1 1 ## 5 1.31125377 1 1 ## 6 -0.55126775 1 1 "],["3.1-predictors-affecting-multiple-responses.html", "3.1 Predictors affecting multiple responses", " 3.1 Predictors affecting multiple responses If we look a little at what simulate_population() assumes underneath with the formulation above (just random effects), we can understand more how we simulate predictors that affect multiple response variable. In the above code, we are essentially simulating a predictor for each trait (individual_effect1 and individual_effect2) with some covariance between them. We can expand the equation above: \\[\\boldsymbol{y}_{ij} = \\boldsymbol{\\beta}_0 + \\boldsymbol{u}_j B_u + \\boldsymbol{\\epsilon}_{ij}B_{\\epsilon}\\] \\[ B_u = \\begin{bmatrix} 1 &amp; 0 \\\\ 0 &amp; 1 \\end{bmatrix} , B_{\\epsilon} = \\begin{bmatrix} 1 &amp; 0 \\\\ 0 &amp; 1 \\end{bmatrix} \\] to include matrices of \\(\\beta\\)s, \\(B\\), the columns of which refer to the response variable, and the rows predictors. In this case they are all identity matrices, which essentially controlling which predictors affects which response (\\(u_1\\) affects \\(y_1\\) but not \\(y_2\\) and vice versa). Internally, simulate_population() does the same thing, and assigns beta as an identity matrix. squid_data &lt;- simulate_population( data_structure= make_structure(structure = &quot;individual(100)&quot;,repeat_obs=10), n_response=2, response_name = c(&quot;body_mass&quot;,&quot;behaviour&quot;), parameters=list( individual = list( vcov =matrix(c(1,0.5,0.5,1),nrow=2,ncol=2,byrow=TRUE), beta= diag(2) ), residual = list( vcov =matrix(c(1,0.5,0.5,1),nrow=2,ncol=2,byrow=TRUE), beta= diag(2) ) ) ) How is this helpful? Well now we could simulate one (or many) predictor(s) that both responses. In the form of an equation we could have \\[\\boldsymbol{y}_{ij} = \\boldsymbol{\\beta}_0 + \\boldsymbol{x}_{i} B_x + \\boldsymbol{u}_j + \\boldsymbol{\\epsilon}_{ij}\\] \\[\\boldsymbol{x}_i \\sim \\mathcal{N}(\\boldsymbol{\\mu}_x, \\Sigma_x)\\] \\[\\boldsymbol{u}_i \\sim \\mathcal{N}(0, \\Sigma_u)\\] \\[\\boldsymbol{\\epsilon}_{i} \\sim \\mathcal{N}(0, \\Sigma_{\\epsilon})\\] where \\(B\\) is a \\(p*q\\) matrix, where \\(p\\) is number of predictors. So if we returned to our original example in Section 1, we have three predictors at the observation level - temperature, rainfall and wind. So \\(B_x\\) would be a 3*2 matrix, with 3 predictors and two responses. Beta &lt;- matrix(c( 0.5, -0.1, 0.2, -0.2, 0.3, -0.1 ),nrow=3,ncol=2,byrow=TRUE) Beta ## [,1] [,2] ## [1,] 0.5 -0.1 ## [2,] 0.2 -0.2 ## [3,] 0.3 -0.1 So here, the environment variables all positively affect body mass (response 1) and negatively affect behaviour (response 2). This then slots easily into our code. squid_data &lt;- simulate_population( data_structure= make_structure(structure = &quot;individual(100)&quot;,repeat_obs=20), n_response=2, parameters= list( individual = list( vcov =matrix(c(1,0.5,0.5,1),nrow=2,ncol=2,byrow=TRUE) ), observation = list( names = c(&quot;temperature&quot;, &quot;rainfall&quot;, &quot;wind&quot;), beta= Beta ), residual = list( vcov= matrix(c(1,0.5,0.5,1),nrow=2,ncol=2,byrow=TRUE) ) ) ) data &lt;- get_population_data(squid_data) head(data) ## y1 y2 individual_effect1 individual_effect2 temperature ## 1 0.2981452 -1.3155845 -0.311252 -0.897568 -1.1453264 ## 2 -0.6873794 -0.6087159 -0.311252 -0.897568 -0.8578652 ## 3 0.5970893 -0.6079079 -0.311252 -0.897568 -0.2261574 ## 4 -1.4274647 -1.3401883 -0.311252 -0.897568 1.8213830 ## 5 1.5506350 -0.6644989 -0.311252 -0.897568 1.1993774 ## 6 -0.3039953 -1.9789316 -0.311252 -0.897568 -1.2945405 ## rainfall wind residual1 residual2 individual squid_pop ## 1 0.5882671 1.1457965 0.7206679 -0.3003161 1 1 ## 2 0.2144061 -0.5558841 0.1766892 0.1903584 1 1 ## 3 1.6741909 0.5743441 0.5142786 0.6593169 1 1 ## 4 0.2989377 -0.8591160 -1.8289570 -0.2866060 1 1 ## 5 0.4251985 -0.2197198 1.2430745 0.4160745 1 1 ## 6 1.1467957 1.0675309 0.1049086 -0.8747054 1 1 # library(MCMCglmm) # mod &lt;- MCMCglmm(cbind(y1,y2)~1,random=~us(trait):individual, rcov=~us(trait):units,data=data,family=rep(&quot;gaussian&quot;,2),verbose=FALSE) # summary(mod) Equally if we want an interaction, we now have to expand the size of what we give to beta, with one \\(\\beta\\) for each response, in a matrix, with \\(q\\) columns. squid_data &lt;- simulate_population( data_structure= make_structure(structure = &quot;individual(100)&quot;,repeat_obs=20), n_response=2, parameters= list( individual = list( vcov =matrix(c(1,0.5,0.5,1),nrow=2,ncol=2,byrow=TRUE) ), observation = list( names = c(&quot;temperature&quot;, &quot;rainfall&quot;, &quot;wind&quot;), beta= Beta ), interactions = list( names = c(&quot;temperature:rainfall&quot;), beta=matrix(c(0.1,-0.3),ncol=2,byrow=TRUE) ), residual = list( vcov= matrix(c(1,0.5,0.5,1),nrow=2,ncol=2,byrow=TRUE) ) ) ) data &lt;- get_population_data(squid_data) head(data) ## y1 y2 individual_effect1 individual_effect2 temperature ## 1 -1.4752163 -0.53377659 -0.2872822 -0.6655179 0.03214917 ## 2 0.1289671 -0.83203811 -0.2872822 -0.6655179 -0.08320398 ## 3 0.7591382 -0.04450337 -0.2872822 -0.6655179 -0.28697095 ## 4 2.1132225 -1.23146725 -0.2872822 -0.6655179 1.92678408 ## 5 -0.8876520 -1.06185793 -0.2872822 -0.6655179 0.40335533 ## 6 0.5234630 -0.94372291 -0.2872822 -0.6655179 0.55847261 ## rainfall wind residual1 residual2 temperature:rainfall individual ## 1 -0.4787747 -0.4815074 -0.9622622 -0.01356718 -0.01539221 1 ## 2 0.5679376 0.2375696 0.2777184 -0.05167259 -0.04725466 1 ## 3 -0.4349687 -0.8358394 1.5151691 0.45918672 0.12482338 1 ## 4 -0.1022663 0.1218843 1.4407051 -0.44064937 -0.19704515 1 ## 5 0.9295396 -0.7546885 -0.7990423 -0.13308504 0.37493476 1 ## 6 -1.2836502 -1.3774485 1.2731618 -0.83189771 -0.71688346 1 ## squid_pop ## 1 1 ## 2 1 ## 3 1 ## 4 1 ## 5 1 ## 6 1 # library(MCMCglmm) # mod &lt;- MCMCglmm(cbind(y1,y2)~1,random=~us(trait):individual, rcov=~us(trait):units,data=data,family=rep(&quot;gaussian&quot;,2),verbose=FALSE) # summary(mod) "],["3.2-one-response-repeatedly-measured-the-other-not.html", "3.2 One response repeatedly measured, the other not", " 3.2 One response repeatedly measured, the other not In some circumstances we might want to simulate two responses, one that varies between measurements and one that doesn’t. For example we might have one fixed measurement of body size for each individual, and repeated measurements of behaviour. We can simply set the variance of the singly measured variable to 0 at that particular level. So for this example: squid_data &lt;- simulate_population( data_structure= make_structure(structure = &quot;individual(100)&quot;,repeat_obs=20), n_response = 2, parameters=list( individual = list( vcov = matrix(c( 1,0.5, 0.5,1 ),nrow=2,ncol=2,byrow=TRUE) ), residual = list( vcov = c(0.8,0) ) ) ) data &lt;- get_population_data(squid_data) "],["3.3-different-distributions.html", "3.3 Different distributions", " 3.3 Different distributions individual &lt;- list( vcov = matrix(c( 1,0.5, 0.5,1 ),nrow=2,ncol=2,byrow=TRUE) ) residual &lt;- list( vcov = matrix(c( 1,0.5, 0.5,1 ),nrow = 2,ncol = 2,byrow=TRUE), beta = matrix(c( 1,0, 0,0 ),nrow = 2,ncol = 2,byrow=TRUE) ) squid_data &lt;- simulate_population( data_structure= make_structure(structure = &quot;individual(100)&quot;,repeat_obs=20), n_response = 2, parameters=list(individual = individual, residual = residual), family=c(&quot;gaussian&quot;,&quot;binomial&quot;), link=c(&quot;identity&quot;,&quot;logit&quot;) ) data &lt;- get_population_data(squid_data) head(data,20) ## y1 y2 individual_effect1 individual_effect2 residual1 residual2 ## 1 0.71929104 0 -0.5257881 -1.042722 1.24507910 2.50335447 ## 2 0.33325030 1 -0.5257881 -1.042722 0.85903836 1.44428517 ## 3 -0.42718617 0 -0.5257881 -1.042722 0.09860189 1.26752630 ## 4 0.44910069 0 -0.5257881 -1.042722 0.97488875 0.39978044 ## 5 -0.62462727 0 -0.5257881 -1.042722 -0.09883921 0.73676976 ## 6 0.12822742 0 -0.5257881 -1.042722 0.65401547 2.32798502 ## 7 -0.10269091 0 -0.5257881 -1.042722 0.42309715 0.97088795 ## 8 -1.16521217 0 -0.5257881 -1.042722 -0.63942411 -1.11697997 ## 9 -2.02498920 0 -0.5257881 -1.042722 -1.49920114 -1.71662806 ## 10 0.84702556 1 -0.5257881 -1.042722 1.37281362 0.31558774 ## 11 -1.13218028 0 -0.5257881 -1.042722 -0.60639222 0.50095716 ## 12 -1.01004461 0 -0.5257881 -1.042722 -0.48425655 0.92650060 ## 13 0.71616352 0 -0.5257881 -1.042722 1.24195158 -1.25932342 ## 14 -0.72239979 1 -0.5257881 -1.042722 -0.19661173 -0.51083678 ## 15 -1.33642792 1 -0.5257881 -1.042722 -0.81063987 -1.35618916 ## 16 -1.95735773 0 -0.5257881 -1.042722 -1.43156967 -1.13993143 ## 17 -0.85504490 0 -0.5257881 -1.042722 -0.32925684 0.03603065 ## 18 1.26558426 0 -0.5257881 -1.042722 1.79137232 2.14512837 ## 19 0.04558226 0 -0.5257881 -1.042722 0.57137032 0.52313819 ## 20 0.88752414 1 -0.5257881 -1.042722 1.41331220 0.87626903 ## individual squid_pop ## 1 1 1 ## 2 1 1 ## 3 1 1 ## 4 1 1 ## 5 1 1 ## 6 1 1 ## 7 1 1 ## 8 1 1 ## 9 1 1 ## 10 1 1 ## 11 1 1 ## 12 1 1 ## 13 1 1 ## 14 1 1 ## 15 1 1 ## 16 1 1 ## 17 1 1 ## 18 1 1 ## 19 1 1 ## 20 1 1 data &lt;- get_population_data(squid_data) "],["3.4-multivariate-random-slopes.html", "3.4 Multivariate Random Slopes", " 3.4 Multivariate Random Slopes Before reading this it is worth checking out how to simulate univariate random slopes in Section 2.4. Here we have to think about the beta matrix. As we saw in an example above, in multivariate models beta can be thought of as switching on and off predictor variables for the response variables. We we can simulate 4 variables, an intercept and slope for each variable, and then use the beta matrix to tell simulate_population which response variable they link to individual &lt;- list( names = c(&quot;ind_int1&quot;,&quot;ind_slope1&quot;,&quot;ind_int2&quot;,&quot;ind_slope2&quot;), vcov = matrix(c( 1, 0.5, 0, 0, 0.5, 1, 0, 0, 0, 0, 1, 0.2, 0, 0, 0.2, 1 ),nrow=4,ncol=4, byrow=TRUE), beta = matrix(c( 1, 0, 0, 0, 0, 1, 0, 0 ),nrow = 4,ncol = 2, byrow=TRUE) ) observation &lt;- list( names=&quot;environment&quot;, beta=matrix(c(0.5,-0.3), ncol=2,byrow=TRUE) ) residual &lt;- list( vcov = matrix(c( 1,0.5, 0.5,1 ),nrow = 2,ncol = 2,byrow=TRUE) ) interactions &lt;- list( names=c(&quot;ind_slope1:environment&quot;,&quot;ind_slope2:environment&quot;), beta= matrix(c( 1,0, 0,1 ), ncol=2,byrow=TRUE) ) squid_data &lt;- simulate_population( data_structure = make_structure(structure = &quot;individual(100)&quot;,repeat_obs=20), n_response = 2, parameters=list( individual = individual, observation = observation, residual = residual, interactions = interactions ) ) data &lt;- get_population_data(squid_data) head(data,20) ## y1 y2 ind_int1 ind_slope1 ind_int2 ind_slope2 environment ## 1 5.9645704 2.9137755 -2.077368 -3.278942 1.25763 0.05766287 -2.85212863 ## 2 1.0398840 1.6374762 -2.077368 -3.278942 1.25763 0.05766287 -1.17738236 ## 3 -0.4401833 0.7571278 -2.077368 -3.278942 1.25763 0.05766287 -0.35861753 ## 4 -3.1023023 0.3740181 -2.077368 -3.278942 1.25763 0.05766287 0.56941572 ## 5 1.0271930 0.5355074 -2.077368 -3.278942 1.25763 0.05766287 -1.19029314 ## 6 -4.6348419 2.6277686 -2.077368 -3.278942 1.25763 0.05766287 1.19495085 ## 7 -2.9226107 1.9356115 -2.077368 -3.278942 1.25763 0.05766287 -0.23240054 ## 8 -5.4887265 0.5051600 -2.077368 -3.278942 1.25763 0.05766287 1.26443122 ## 9 -3.3095597 3.3006845 -2.077368 -3.278942 1.25763 0.05766287 1.37812284 ## 10 2.3956917 1.9750491 -2.077368 -3.278942 1.25763 0.05766287 -1.66791032 ## 11 -3.0158890 -0.1913344 -2.077368 -3.278942 1.25763 0.05766287 0.24947043 ## 12 -2.5032658 -0.5935247 -2.077368 -3.278942 1.25763 0.05766287 0.09862542 ## 13 -4.2034435 -0.7978834 -2.077368 -3.278942 1.25763 0.05766287 0.08779494 ## 14 -7.1099119 -1.9438330 -2.077368 -3.278942 1.25763 0.05766287 1.50568552 ## 15 -5.1929793 2.0242915 -2.077368 -3.278942 1.25763 0.05766287 1.23433537 ## 16 -3.8947619 1.6117452 -2.077368 -3.278942 1.25763 0.05766287 0.31679603 ## 17 -0.9437016 0.8657072 -2.077368 -3.278942 1.25763 0.05766287 -0.70152517 ## 18 -0.8672693 -0.8645813 -2.077368 -3.278942 1.25763 0.05766287 -0.91219027 ## 19 -2.5933184 1.1027425 -2.077368 -3.278942 1.25763 0.05766287 0.30478046 ## 20 4.0778526 2.4288065 -2.077368 -3.278942 1.25763 0.05766287 -1.76307523 ## residual1 residual2 ind_slope1:environment ind_slope2:environment ## 1 0.1160375 0.96496923 9.3519652 -0.164461926 ## 2 -0.1546256 0.09452311 3.8605689 -0.067891248 ## 3 0.6406074 -0.58740809 1.1758862 -0.020678916 ## 4 0.5574392 -0.74562093 -1.8670813 0.032834145 ## 5 -0.2031949 -1.01057441 3.9029025 -0.068635720 ## 6 0.7632257 1.65972001 -3.9181749 0.068904297 ## 7 -1.4910703 0.62166269 0.7620280 -0.013400883 ## 8 0.1024230 -0.44605095 -4.1459970 0.072910735 ## 9 2.5975322 2.37702528 -4.5187853 0.079466520 ## 10 -0.1619668 0.31322288 5.4689817 -0.096176498 ## 11 -0.2452570 -1.38850807 -0.8179992 0.014385182 ## 12 -0.1518234 -1.82725366 -0.3233871 0.005687025 ## 13 -1.8820984 -2.03423703 -0.2878745 0.005062508 ## 14 -0.8483306 -2.83657912 -4.9370559 0.086822150 ## 15 0.3145355 1.06578725 -4.0473145 0.071175322 ## 16 -0.9370360 0.43088702 -1.0387559 0.018267369 ## 17 -0.8158315 -0.56192798 2.3002606 -0.040451956 ## 18 -1.3248253 -2.34326848 2.9910193 -0.052599510 ## 19 0.3310170 -0.08102745 -0.9993575 0.017574516 ## 20 1.2557363 0.74391836 5.7810220 -0.101663980 ## individual squid_pop ## 1 1 1 ## 2 1 1 ## 3 1 1 ## 4 1 1 ## 5 1 1 ## 6 1 1 ## 7 1 1 ## 8 1 1 ## 9 1 1 ## 10 1 1 ## 11 1 1 ## 12 1 1 ## 13 1 1 ## 14 1 1 ## 15 1 1 ## 16 1 1 ## 17 1 1 ## 18 1 1 ## 19 1 1 ## 20 1 1 "],["4-animal.html", "4 Genetic effects", " 4 Genetic effects This vignette assumes that you are generally happy with how the sim_population() function works. "],["4.1-va.html", "4.1 Additive genetics effects", " 4.1 Additive genetics effects In order to simulate breeding values (additive genetic effects), we can provide the simulate_population() function with the relatedness structure in the population. The simplest way to do this is providing a pedigree using the the pedigree argument (a genetic relatedness matrix could also be given to the cov_str argument). The input to this argument needs to be a list, and the name of the pedigree in the list links it with the item in the parameter list. NOTE the simulate_population function has very little error checking of pedigree structure at the moment When simulating breeding values, all individuals in pedigree need to be in the data_structure and vice versa. Having unsampled individuals (for example the base population) can be achieved in the sampling stage (not implemented yet). Lets start by importing a pedigree from the pedtricks package library(squidSim) library(nadiv) library(gremlin) library(pedtricks) data(gryphons) ped &lt;- fix_ped(gryphons[,1:3]) head(ped) ## id dam sire ## 1 204 &lt;NA&gt; &lt;NA&gt; ## 2 205 &lt;NA&gt; &lt;NA&gt; ## 3 206 &lt;NA&gt; &lt;NA&gt; ## 4 207 &lt;NA&gt; &lt;NA&gt; ## 5 208 &lt;NA&gt; &lt;NA&gt; ## 6 209 &lt;NA&gt; &lt;NA&gt; names(ped)[1]&lt;-&quot;animal&quot; We can use this pedigree as a data_structure squid_data &lt;- simulate_population( data_structure = ped[,1:3], pedigree = list(animal=ped[,1:3]), parameters =list( animal = list( vcov = 0.2 ), residual = list( vcov = 0.5 ) ) ) data &lt;- get_population_data(squid_data) head(data) ## y animal_effect residual animal dam sire squid_pop ## 1 -2.3553680 -0.2981992 -2.0571688 204 &lt;NA&gt; &lt;NA&gt; 1 ## 2 -0.0831304 0.2218079 -0.3049383 205 &lt;NA&gt; &lt;NA&gt; 1 ## 3 -0.1690798 -0.2820988 0.1130190 206 &lt;NA&gt; &lt;NA&gt; 1 ## 4 1.6868459 0.6530291 1.0338168 207 &lt;NA&gt; &lt;NA&gt; 1 ## 5 -0.4311466 -0.5338738 0.1027271 208 &lt;NA&gt; &lt;NA&gt; 1 ## 6 -0.1819541 -0.4747195 0.2927654 209 &lt;NA&gt; &lt;NA&gt; 1 We can use the grelim pacakge to run a REML animal model Ainv &lt;- makeAinv(ped)$Ainv mod &lt;- gremlin(y~1, random=~ animal,data=data,ginverse=list(animal=Ainv)) ## gremlin started: 18:14:56 ## &#39;as(&lt;dsyMatrix&gt;, &quot;dsCMatrix&quot;)&#39; is deprecated. ## Use &#39;as(., &quot;CsparseMatrix&quot;)&#39; instead. ## See help(&quot;Deprecated&quot;) and help(&quot;Matrix-deprecated&quot;). ## 1 of max 20 lL:-7685.481081 took 0.0037 sec. ## 2 of max 20 lL:-1671.313492 took 0.0026 sec. ## 3 of max 20 lL:-1604.018169 took 0.0026 sec. ## 4 of max 20 lL:-1601.696981 took 0.0026 sec. ## 5 of max 20 lL:-1601.692845 took 0.0026 sec. ## 6 of max 20 lL:-1601.692845 took 0.0026 sec. ## 7 of max 20 lL:-1601.692845 took 0.0026 sec. ## ## *** REML converged *** ## ## gremlin ended: 18:14:56 summary(mod) ## ## Linear mixed model fit by REML [&#39; gremlin &#39;] ## REML log-likelihood: -1601.693 ## lambda: FALSE ## ## elapsed time for model: 0.0564 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -3.05039 -0.54998 0.00371 0.54487 3.14710 ## ## (co)variance parameters: ~animal ## rcov: ~units ## Estimate Std. Error ## G.animal 0.2854 0.02908 ## ResVar1 0.4477 0.02554 ## ## (co)variance parameter sampling correlations: ## G.animal ResVar1 ## G.animal 1.0000 -0.8469 ## ResVar1 -0.8469 1.0000 ## ## Fixed effects: y ~ 1 ## Estimate Std. Error z value ## (Intercept) -0.02358 0.01526 -1.545 We don’t have to simulate a phenotype for everyone in the pedigree, so can include a subset of IDs in the data strcuture ds &lt;- data.frame(animal =ped[sample(1:nrow(ped),1000,replace=FALSE),1]) squid_data &lt;- simulate_population( data_structure = ds, pedigree = list(animal=ped[,1:3]), parameters =list( animal = list( vcov = 0.2 ), residual = list( vcov = 0.5 ) ) ) data &lt;- get_population_data(squid_data) head(data) ## y animal_effect residual animal squid_pop ## 1 -0.46968357 -0.17338301 -0.29630056 3380 1 ## 2 -0.08352477 -0.17213302 0.08860825 362 1 ## 3 -1.48977040 -0.85945395 -0.63031645 1918 1 ## 4 -0.20485162 -0.50879642 0.30394481 2708 1 ## 5 0.39879740 -0.08200417 0.48080157 4287 1 ## 6 -0.59120933 -0.19983313 -0.39137620 3418 1 Ainv &lt;- makeAinv(ped)$Ainv mod &lt;- gremlin(y~1, random=~ animal,data=data,ginverse=list(animal=Ainv)) ## gremlin started: 11:24:44 ## &#39;as(&lt;dsyMatrix&gt;, &quot;dsCMatrix&quot;)&#39; is deprecated. ## Use &#39;as(., &quot;CsparseMatrix&quot;)&#39; instead. ## See help(&quot;Deprecated&quot;) and help(&quot;Matrix-deprecated&quot;). ## 1 of max 20 lL:-1551.356413 took 0.0034 sec. ## 2 of max 20 lL:-418.535368 took 0.0023 sec. ## 3 of max 20 lL:-365.175306 took 0.0022 sec. ## 4 of max 20 lL:-359.174824 took 0.0022 sec. ## 5 of max 20 lL:-359.005605 took 0.0022 sec. ## 6 of max 20 lL:-359.005415 took 0.0022 sec. ## 7 of max 20 lL:-359.005415 took 0.0022 sec. ## ## *** REML converged *** ## ## gremlin ended: 11:24:44 summary(mod) ## ## Linear mixed model fit by REML [&#39; gremlin &#39;] ## REML log-likelihood: -359.0054 ## lambda: FALSE ## ## elapsed time for model: 0.0457 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -2.43366 -0.45542 0.02354 0.43253 2.86515 ## ## (co)variance parameters: ~animal ## rcov: ~units ## Estimate Std. Error ## G.animal 0.4207 0.09582 ## ResVar1 0.3480 0.08755 ## ## (co)variance parameter sampling correlations: ## G.animal ResVar1 ## G.animal 1.0000 -0.9299 ## ResVar1 -0.9299 1.0000 ## ## Fixed effects: y ~ 1 ## Estimate Std. Error z value ## (Intercept) -0.04197 0.03176 -1.321 We might want to simulate repeated measurements to allow estimation of permanent environment effects. The simplest way to do this is to create a duplicated column in the data structure of the individual IDs. Permanent environment effects that are not linked to the pedigree can then be simulated. NOTICE! The instructions given for simulating permanent environment effects using squidSim were incorrect in the vignette prior to version 0.2.0 (updated in September 2025). ## make data structure with two observations per individual, with ID duplicated in two columns, animal and individual, and link the animal column in the data structure to the pedigree ds &lt;- data.frame(animal=rep(ped[,1], 2),individual=rep(ped[,1], 2)) squid_data &lt;- simulate_population( data_structure = ds, pedigree=list(animal=ped), parameters = list( animal = list( vcov = 0.2 ), individual = list( vcov = 0.3 ), residual = list( vcov = 0.5 ) ) ) data &lt;- get_population_data(squid_data) head(data) ## y animal_effect individual_effect residual animal individual ## 1 -0.7812849 0.4665620 -1.0389875 -0.2088594 204 204 ## 2 -0.3499417 -0.9695562 0.2860528 0.3335617 205 205 ## 3 -0.7490084 -0.5394729 0.2739732 -0.4835087 206 206 ## 4 -1.1704516 -0.2701808 0.1314451 -1.0317159 207 207 ## 5 0.2931743 0.1025247 -0.6129429 0.8035925 208 208 ## 6 -0.1245506 0.7061392 -0.1828131 -0.6478767 209 209 ## squid_pop ## 1 1 ## 2 1 ## 3 1 ## 4 1 ## 5 1 ## 6 1 Ainv &lt;- makeAinv(ped)$Ainv mod_pe &lt;- gremlin(y~1, random=~ animal + individual,data=data,ginverse=list(animal=Ainv)) ## gremlin started: 11:24:44 ## 1 of max 20 lL:-12123.358564 took 0.0051 sec. ## 2 of max 20 lL:-4380.793795 took 0.0043 sec. ## 3 of max 20 lL:-4212.077157 took 0.0042 sec. ## 4 of max 20 lL:-4204.524508 took 0.0042 sec. ## 5 of max 20 lL:-4204.496825 took 0.0042 sec. ## 6 of max 20 lL:-4204.496825 took 0.0042 sec. ## 7 of max 20 lL:-4204.496825 took 0.0041 sec. ## ## *** REML converged *** ## ## gremlin ended: 11:24:44 summary(mod_pe) ## ## Linear mixed model fit by REML [&#39; gremlin &#39;] ## REML log-likelihood: -4204.497 ## lambda: FALSE ## ## elapsed time for model: 0.0596 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -3.8558 -0.5524 -0.0036 0.5431 3.0406 ## ## (co)variance parameters: ~animal + individual ## rcov: ~units ## Estimate Std. Error ## G.animal 0.2237 0.029221 ## G.individual 0.3022 0.027781 ## ResVar1 0.4947 0.009977 ## ## (co)variance parameter sampling correlations: ## G.animal G.individual ResVar1 ## G.animal 1.000e+00 -0.8268 -1.794e-15 ## G.individual -8.268e-01 1.0000 -1.796e-01 ## ResVar1 -1.977e-15 -0.1796 1.000e+00 ## ## Fixed effects: y ~ 1 ## Estimate Std. Error z value ## (Intercept) 0.002897 0.01537 0.1885 "],["4.2-multivariate-genetic-effects.html", "4.2 Multivariate genetic effects", " 4.2 Multivariate genetic effects We can simulate genetic effects affecting multiple phenotypes and the covariance between them, by specifying the number of response variables, and a covariance matrix, instead of only a variance. squid_data &lt;- simulate_population( data_structure = ped, pedigree = list(animal = ped), n_response=2, parameters = list( animal = list( vcov = diag(2) ), residual = list( vcov = diag(2) ) ) ) data &lt;- get_population_data(squid_data) head(data) ## y1 y2 animal_effect1 animal_effect2 residual1 residual2 ## 1 0.6642658 0.83471076 0.46407220 0.22094082 0.2001936 0.6137699 ## 2 -0.7466087 0.14747280 0.54421651 0.52761540 -1.2908253 -0.3801426 ## 3 1.6963890 -0.40456141 0.39385325 -0.30347849 1.3025357 -0.1010829 ## 4 1.9764612 0.85993234 0.08271504 0.26908060 1.8937461 0.5908517 ## 5 -0.8080648 -0.09793586 -1.85489445 0.07503407 1.0468296 -0.1729699 ## 6 3.0311582 0.96837367 2.32009932 0.25440902 0.7110589 0.7139646 ## animal dam sire squid_pop ## 1 204 &lt;NA&gt; &lt;NA&gt; 1 ## 2 205 &lt;NA&gt; &lt;NA&gt; 1 ## 3 206 &lt;NA&gt; &lt;NA&gt; 1 ## 4 207 &lt;NA&gt; &lt;NA&gt; 1 ## 5 208 &lt;NA&gt; &lt;NA&gt; 1 ## 6 209 &lt;NA&gt; &lt;NA&gt; 1 library(MCMCglmm) Ainv&lt;-inverseA(ped)$Ainv mod &lt;- MCMCglmm(cbind(y1,y2)~1, random=~us(trait):animal, rcov=~us(trait):units, data=data, ginverse=list(animal=Ainv), family=rep(&quot;gaussian&quot;,2), verbose=FALSE) summary(mod) ## ## Iterations = 3001:12991 ## Thinning interval = 10 ## Sample size = 1000 ## ## DIC: 32469.06 ## ## G-structure: ~us(trait):animal ## ## post.mean l-95% CI u-95% CI eff.samp ## traity1:traity1.animal 0.99346 0.82773 1.1631 162.4 ## traity2:traity1.animal 0.01649 -0.09408 0.1259 211.7 ## traity1:traity2.animal 0.01649 -0.09408 0.1259 211.7 ## traity2:traity2.animal 1.06973 0.87654 1.2265 202.6 ## ## R-structure: ~us(trait):units ## ## post.mean l-95% CI u-95% CI eff.samp ## traity1:traity1.units 1.06566 0.9433 1.21635 206.0 ## traity2:traity1.units -0.05158 -0.1421 0.04004 209.5 ## traity1:traity2.units -0.05158 -0.1421 0.04004 209.5 ## traity2:traity2.units 0.97807 0.8336 1.10499 211.3 ## ## Location effects: cbind(y1, y2) ~ 1 ## ## post.mean l-95% CI u-95% CI eff.samp pMCMC ## (Intercept) -0.02171 -0.05669 0.01237 893.3 0.242 "],["4.3-sex-specific-genetic-variance-and-inter-sexual-genetic-correlations.html", "4.3 Sex specific genetic variance and inter-sexual genetic correlations", " 4.3 Sex specific genetic variance and inter-sexual genetic correlations ds &lt;- data.frame(animal=gryphons[,&quot;id&quot;],sex=sample(c(&quot;Female&quot;,&quot;Male&quot;),nrow(gryphons), replace=TRUE)) squid_data &lt;- simulate_population( parameters = list( sex=list( fixed=TRUE, names=c(&quot;Female&quot;,&quot;Male&quot;), beta=c(-0.5,0.5) ), animal= list( names = c(&quot;G_female&quot;,&quot;G_male&quot;), vcov =matrix(c(0.1,-0.1,-0.1,0.4), nrow=2, ncol=2 ,byrow=TRUE) ), residual = list( names=&quot;residual&quot;, vcov = 0.1 ) ), data_structure = ds, pedigree = list(animal=ped), model = &quot;y = Female + Male + I(Female)*G_female + I(Male)*G_male + residual&quot; ) data &lt;- get_population_data(squid_data) head(data) ## y Female Male G_female G_male residual animal sex ## 1 -1.1406269 1 0 -0.41650798 0.8611695 -0.22411895 204 Female ## 2 -0.9338681 1 0 0.02895999 0.7161771 -0.46282805 205 Female ## 3 -0.5726704 1 0 -0.11908647 0.3606215 0.04641609 206 Female ## 4 0.5511020 0 1 -0.45076138 0.2253053 -0.17420333 207 Male ## 5 -0.6838055 1 0 -0.12133713 -0.3310633 -0.06246839 208 Female ## 6 -0.1827386 0 1 0.33321284 -0.6581778 -0.02456084 209 Male ## squid_pop ## 1 1 ## 2 1 ## 3 1 ## 4 1 ## 5 1 ## 6 1 par(mfrow=c(1,2)) boxplot(y~factor(sex),data) plot(G_female~G_male,data) "],["4.4-IGE.html", "4.4 Indirect Genetic Effects", " 4.4 Indirect Genetic Effects Indirect genetic effects are a bit more difficult to code. Lets take the example of maternal genetic effects. The maternal genetic effect that affects an individual’s phenotype, is that of its mother, not itself. Here we can use [] to index the levels of the random effects within the formula. We need to be careful here as internally in simulate_population() the indexing of the factors in the data structure is done independently. We therefore need to generate a index for the mothers that links to the individual. We can do this using the index_link argument - in the code below we create a new factor to index with, called dam_link, that is the dam factor in our data structure, that has been indexed to match the animal factor. Using this indexing trick, we can simulate the direct genetic and maternal genetic effects that an individual has (and the covariance between them), as well as generating an individual’s phenotype from its own direct genetic effects, and its mother’s maternal genetic effect. squid_data &lt;- simulate_population( parameters=list( animal = list( names=c(&quot;direct&quot;,&quot;maternal&quot;), vcov = matrix(c(1,0.3,0.3,0.5),2,2) ), residual = list( names=&quot;residual&quot;, vcov = 0.5 ) ), data_structure=ped, pedigree=list(animal=ped), index_link=list(dam_link=&quot;dam-animal&quot;), model = &quot;y = direct + maternal[dam_link] + residual&quot; ) ## Warning: Not all levels are of dam are present in animal meaning that there ## will be NAs in the new grouping factor data &lt;- get_population_data(squid_data) head(data) ## y direct maternal residual animal dam sire squid_pop ## 1 NA -1.3868139 -0.958645316 -0.53517980 204 &lt;NA&gt; &lt;NA&gt; 1 ## 2 NA -0.3557084 -0.020020959 -0.05060699 205 &lt;NA&gt; &lt;NA&gt; 1 ## 3 NA -1.6063940 -0.008095092 0.44336246 206 &lt;NA&gt; &lt;NA&gt; 1 ## 4 NA -0.5702206 1.481172744 -0.31267001 207 &lt;NA&gt; &lt;NA&gt; 1 ## 5 NA -0.6878199 1.331302491 -0.68215405 208 &lt;NA&gt; &lt;NA&gt; 1 ## 6 NA -0.4438793 0.168884393 -0.70437684 209 &lt;NA&gt; &lt;NA&gt; 1 "],["4.5-gxe.html", "4.5 GxE", " 4.5 GxE squid_data &lt;- simulate_population( parameters = list( animal = list( names = c(&quot;G_int&quot;,&quot;G_slope&quot;), mean = c(0,0), vcov = matrix(c(1,0.3,0.3,0.5),ncol=2,nrow=2,byrow=TRUE), beta = c(1,0) ), observation= list( names = c(&quot;environment&quot;), vcov = c(0.2) ), residual = list( names = c(&quot;residual&quot;), vcov = c(0.5) ), interactions=list( names = &quot;G_slope:environment&quot;, beta = 1 ) ), data_structure=rbind(ped,ped,ped,ped,ped), pedigree = list(animal=ped) ) data &lt;- get_population_data(squid_data) library(lme4) short_summary &lt;- function(x) print(summary(x), correlation=FALSE, show.resids=FALSE, ranef.comp = c(&quot;Variance&quot;)) short_summary(lmer(y ~ environment + (1+environment|animal),data)) ## Linear mixed model fit by REML [&#39;lmerMod&#39;] ## Formula: y ~ environment + (1 + environment | animal) ## Data: data ## ## REML criterion at convergence: 66750.8 ## ## Random effects: ## Groups Name Variance Cov ## animal (Intercept) 0.9920 ## environment 0.5068 0.30 ## Residual 0.4955 ## Number of obs: 24590, groups: animal, 4918 ## ## Fixed effects: ## Estimate Std. Error t value ## (Intercept) 0.02510 0.01497 1.677 ## environment 0.98595 0.01580 62.386 "],["4.6-dominance.html", "4.6 Dominance", " 4.6 Dominance Here we can make use of the dominance relatedness matrices that can be generated in the nadiv package data(warcolak) pedD &lt;- warcolak[,1:3] Dmats &lt;- makeD(pedD) ## starting to make D....done ## starting to invert D....done Dmat &lt;- Dmats$D We can input this into simulate_population() with the cov_str argument: ds &lt;- data.frame(animal = pedD[,1], animalD = pedD[,1]) squid_data &lt;- simulate_population( data_structure = ds, pedigree = list(animal=pedD[,1:3]), cov_str = list(animalD=Dmat), parameters =list( animal = list( vcov = 0.2 ), animalD = list( vcov = 0.2 ), residual = list( vcov = 0.5 ) ) ) data &lt;- get_population_data(squid_data) We can then run a model to check the simulation, using {gremlin}, with inverse A and D matrices: Dinv &lt;- Dmats$Dinv Ainv_dom &lt;- makeAinv(pedD)$Ainv mod_dom &lt;- gremlin(y~1, random=~ animal + animalD,data=data,ginverse=list(animal=Ainv_dom,animalD=Dinv)) ## gremlin started: 11:24:45 ## 1 of max 20 lL:-5762.227161 took 0.0061 sec. ## 2 of max 20 lL:-2494.762867 took 0.0049 sec. ## 3 of max 20 lL:-2312.124280 took 0.0049 sec. ## 4 of max 20 lL:-2299.455179 took 0.0048 sec. ## 5 of max 20 lL:-2299.355390 took 0.0048 sec. ## 6 of max 20 lL:-2299.355382 took 0.0048 sec. ## 7 of max 20 lL:-2299.355382 took 0.0048 sec. ## ## *** REML converged *** ## ## gremlin ended: 11:24:45 summary(mod_dom) ## ## Linear mixed model fit by REML [&#39; gremlin &#39;] ## REML log-likelihood: -2299.355 ## lambda: FALSE ## ## elapsed time for model: 0.0863 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -2.92188 -0.54659 0.02061 0.55849 3.09950 ## ## (co)variance parameters: ~animal + animalD ## rcov: ~units ## Estimate Std. Error ## G.animal 0.2068 0.02422 ## G.animalD 0.1588 0.04980 ## ResVar1 0.5437 0.04572 ## ## (co)variance parameter sampling correlations: ## G.animal G.animalD ResVar1 ## G.animal 1.00000 -0.2807 -0.01946 ## G.animalD -0.28069 1.0000 -0.89553 ## ResVar1 -0.01946 -0.8955 1.00000 ## ## Fixed effects: y ~ 1 ## Estimate Std. Error z value ## (Intercept) -0.02196 0.02418 -0.9084 "],["4.7-inbreeding-depression.html", "4.7 Inbreeding depression", " 4.7 Inbreeding depression Coming soon… "],["4.8-genetic-groups.html", "4.8 Genetic Groups", " 4.8 Genetic Groups Coming soon… "],["5-phylogenetic.html", "5 Phylogenetic Effects ", " 5 Phylogenetic Effects "],["5.1-brownian-motion.html", "5.1 Brownian motion", " 5.1 Brownian motion We can simulate some data using the bird families phylogeny from the {ape} package. Here we have a grouping variables called taxa in the data structure, which links to the phylogeny. We can then specify the phylogenetic variance. library(ape) data(bird.families) squid_dat &lt;- simulate_population( data_structure=data.frame(taxon=bird.families$tip.label), parameters=list( taxon=list( vcov=1 ), residual=list( vcov=1 ) ), phylogeny=list(taxon=bird.families) ) pop_dat &lt;- get_population_data(squid_dat) Run model to check library(MCMCglmm) Ainv&lt;-inverseA(bird.families)$Ainv prior&lt;-list( R=list(V=1, nu=0.002), G=list(G1=list(V=1, nu=0.002))) model1&lt;-MCMCglmm(y~1, random=~taxon, ginverse=list(taxon=Ainv), data=pop_dat, prior=prior, verbose=FALSE, nitt=13000, burnin=3000, thin=10) summary(model1) ## ## Iterations = 3001:12991 ## Thinning interval = 10 ## Sample size = 1000 ## ## DIC: 420.2962 ## ## G-structure: ~taxon ## ## post.mean l-95% CI u-95% CI eff.samp ## taxon 1.108 0.209 2.469 60.44 ## ## R-structure: ~units ## ## post.mean l-95% CI u-95% CI eff.samp ## units 1.034 0.1187 1.637 82.43 ## ## Location effects: y ~ 1 ## ## post.mean l-95% CI u-95% CI eff.samp pMCMC ## (Intercept) 0.0956 -0.5763 0.7307 986.9 0.736 "],["6-temporal-and-spatial-effects.html", "6 Temporal and Spatial Effects ", " 6 Temporal and Spatial Effects "],["6.1-simple-temporal-effects.html", "6.1 Simple Temporal Effects", " 6.1 Simple Temporal Effects We might have measured a variable over the course of a certain time period (e.g. 20 years). We might expect that there is stochastic year-to-year variation, which we can simulate already. However we might also want to simulate patterns in that temporal data. We can treat the levels associated with a particular grouping factor (e.g. year) as both a factor and continuous. To treat a grouping factor as continuous, we use covariate=TRUE in the parameter list. In this way we can simulate a linear effect of year: squid_data &lt;- simulate_population( data_structure= make_structure(structure = &quot;year(20) + sex(2)/individual(50)&quot;,repeat_obs=20), parameters=list( year_cont = list( group=&quot;year&quot;, names= &quot;year_cont&quot;, covariate=TRUE, beta=0.3 ), year = list( vcov = 0.8 ), residual=list( vcov = 1 ) ) ) note we have specified group in the parameter list. This enables us to link a set of parameters to the grouping factor in the data structure. This doesn’t have to be specified and defaults to the name of the list item. data &lt;- get_population_data(squid_data) head(data) ## y year_cont year_effect residual year sex individual squid_pop ## 1 1.1436403 1 2.21821 -1.3745698 1 1 1 1 ## 2 3.0559676 1 2.21821 0.5377575 1 1 1 1 ## 3 4.2148492 1 2.21821 1.6966392 1 1 1 1 ## 4 0.6152528 1 2.21821 -1.9029573 1 1 1 1 ## 5 1.8172122 1 2.21821 -0.7009978 1 1 1 1 ## 6 1.7139274 1 2.21821 -0.8042827 1 1 1 1 plot(y ~ year_cont, data) Here we can see there is within year variation, year to year variation, as well as a linear directional year effect. lmer(y ~ year_cont + (1|year), data) ## Linear mixed model fit by REML [&#39;lmerMod&#39;] ## Formula: y ~ year_cont + (1 | year) ## Data: data ## REML criterion at convergence: 113318.3 ## Random effects: ## Groups Name Std.Dev. ## year (Intercept) 0.9652 ## Residual 0.9956 ## Number of obs: 40000, groups: year, 20 ## Fixed Effects: ## (Intercept) year_cont ## 0.5669 0.2838 In a similar way we can also simulate a quadratic effect of time. squid_data &lt;- simulate_population( data_structure = make_structure(structure = &quot;year(20) + sex(2)/individual(50)&quot;,repeat_obs=20), parameters=list( year_cont = list( group=&quot;year&quot;, names= c(&quot;year_cont&quot;), covariate=TRUE, beta=c(0.3) ), interactions=list( names= c(&quot;year_cont:year_cont&quot;), beta=c(-0.05) ), year = list( vcov = 1 ), residual=list( vcov = 0.8 ) ) ) data &lt;- get_population_data(squid_data) plot(y~year_cont,data) "],["6.2-cyclical-temporal-effects.html", "6.2 Cyclical Temporal Effects", " 6.2 Cyclical Temporal Effects The squidR function in the {squid} R package uses the sinusoidal equation to implement cyclical temporal effects: \\[ y = A sin(B(x - C)) + D \\] where A is the amplitude, \\(B/2\\pi\\) is the period \\(C/B\\) is the horizontal shift and D is the vertical shift. We can visualise this time &lt;- 1:20 amplitude &lt;- 10 # |A| = the amplitude period &lt;- 10 h_shift &lt;- 3 v_shift &lt;- 5 B &lt;- (2*pi) / abs(period) # 2pi/|B| = the period cyclic_effect &lt;- amplitude*sin(B*time - B^2*h_shift ) + v_shift plot(cyclic_effect~time) We can simulate this using the model part of the simulate_population(), adding the extra parameters for the cyclical effects into the year_cont part of the list. squid_data &lt;- simulate_population( data_structure= make_structure(structure = &quot;year(20) + sex(2)/individual(50)&quot;,repeat_obs=1), parameters=list( year_cont = list( group=&quot;year&quot;, names= &quot;linear_effect&quot;, covariate=TRUE, beta=0.3, amplitude = 2, # |A| = the amplitude period = 10, h_shift = 3, v_shift = 5 ), year = list( vcov = 1.2 ), residual=list( vcov = 1 ) ), model=&quot; B =(2*pi) / abs(period); cyclic_effect = amplitude*sin(B*I(linear_effect) - B^2*h_shift ) + v_shift; y = linear_effect + cyclic_effect + year_effect + residual&quot; ) data &lt;- get_population_data(squid_data) plot(y~year,data) "],["6.3-temporalauto.html", "6.3 Temporal Autocorrelation", " 6.3 Temporal Autocorrelation ar1_cor &lt;- function(n, rho) { exponent &lt;- abs(matrix(1:n - 1, nrow = n, ncol = n, byrow = TRUE) - (1:n - 1)) rho^exponent } temp_mat&lt;-ar1_cor(n=100,rho=0.9) colnames(temp_mat)&lt;-rownames(temp_mat)&lt;-1:100 ds &lt;- data.frame(day=1:100) sim_dat_ta&lt;-simulate_population( seed=25, data_structure = ds, parameters = list( day = list(vcov=4), residual = list(vcov=1) ), cov_str = list(day=temp_mat) ) dat_ta&lt;-get_population_data(sim_dat_ta) head(dat_ta) ## y day_effect residual day squid_pop ## 1 3.6334258 3.835942 -0.2025162 1 1 ## 2 2.0960169 3.270739 -1.1747219 2 1 ## 3 0.6243599 1.979511 -1.3551508 3 1 ## 4 1.5844086 1.307931 0.2764777 4 1 ## 5 1.4873109 1.145398 0.3419127 5 1 ## 6 1.0725710 2.048936 -0.9763652 6 1 all(unique(ds$day) %in% rownames(temp_mat)) ## [1] TRUE sim_dat_no_ta&lt;-simulate_population( seed=23, data_structure = ds, parameters = list( day = list(vcov=4), residual = list(vcov=1) ) ) dat_no_ta&lt;-get_population_data(sim_dat_no_ta) par(mfrow=c(2,1)) plot(y~day,dat_ta, type=&quot;l&quot;, main=&quot;Temporal Autocorrelation&quot;) plot(y~day,dat_no_ta, type=&quot;l&quot;, main=&quot;No Autocorrelation&quot;) "],["6.4-spatialauto.html", "6.4 Spatial Autocorrelation", " 6.4 Spatial Autocorrelation Spatial autocorrelation can be simulate by passing a spatial correlation matrix to the cov_str argument of simulate_population(). First we need some kind of spatial autocorrelation matrix. This is a large correlation matrix, showing how close all the locations are to each other. We create different kinds of these. Here, we use the corClasses structures in the nlme package. To demonstrate, we generate a exponential spatial correlation matrix, with strong autocorrelation. library(nlme) ## ## Attaching package: &#39;nlme&#39; ## The following object is masked from &#39;package:lme4&#39;: ## ## lmList ## The following object is masked from &#39;package:dplyr&#39;: ## ## collapse library(squidSim) ds &lt;- make_structure(&quot;location(2500)&quot;) locations &lt;- matrix(1:2500,nrow=50,ncol=50) locations2&lt;-as.data.frame(t(sapply(1:2500,function(x)which(locations==x, arr.ind=TRUE)))) colnames(locations2) &lt;- c(&quot;x&quot;,&quot;y&quot;) cs1Exp &lt;- corExp(5, form = ~ x + y) cs1Exp &lt;- Initialize(cs1Exp, locations2) spM&lt;- corMatrix(cs1Exp) colnames(spM) &lt;- rownames(spM) &lt;- 1:2500 We can feed this matrix into the cor_str argument of simulate_population(). Here we simulate with and without spatial autocorrelation to show the difference. sim_dat_auto&lt;-simulate_population( seed=22, data_structure = ds, parameters = list( location = list(vcov=4), residual = list(vcov=1) ), cov_str = list(location=spM) ) dat_auto&lt;-get_population_data(sim_dat_auto) sim_dat_no&lt;-simulate_population( seed=27, data_structure = ds, parameters = list( location = list(vcov=4), residual = list(vcov=1) ) ) dat_no&lt;-get_population_data(sim_dat_no) library(viridis) ## Loading required package: viridisLite ## ## Attaching package: &#39;viridis&#39; ## The following object is masked from &#39;package:scales&#39;: ## ## viridis_pal color_scale &lt;- viridis(20) dat_auto$y_group &lt;- as.numeric(cut(dat_auto$y, breaks=20)) dat_no$y_group &lt;- as.numeric(cut(dat_no$y, breaks=20)) par(mfrow=c(1,2)) plot(y~x,locations2, pch=19, col=color_scale[dat_auto$y_group], cex=1, main=&quot;Spatial Autocorrelation&quot;) plot(y~x,locations2, pch=19, col=color_scale[dat_no$y_group], cex=1, main=&quot;No Autocorrelation&quot;) 6.4.1 Example: Species occurrence data with spatial autocorrelation library(nlme) library(squidSim) ds &lt;- make_structure(&quot;location(2500)&quot;) locations &lt;- matrix(1:2500,nrow=50,ncol=50) locations2&lt;-as.data.frame(t(sapply(1:2500,function(x)which(locations==x, arr.ind=TRUE)))) colnames(locations2) &lt;- c(&quot;x&quot;,&quot;y&quot;) cs1Exp &lt;- corExp(3, form = ~ x + y) cs1Exp &lt;- Initialize(cs1Exp, locations2) spM&lt;- corMatrix(cs1Exp) colnames(spM) &lt;- rownames(spM) &lt;- 1:2500 sim_dat&lt;-simulate_population( seed=236, data_structure = ds, n_response=2, response_names = c(&quot;occurrence&quot;,&quot;observation&quot;), parameters = list( intercept= c(-3,0), location = list(vcov=c(4,0)), # age=list(covariate=TRUE, beta=matrix(c(-0.2,0),ncol=2)), residual=list(vcov=c(0,0)) ), cov_str = list(location=spM), family= &quot;binomial&quot;, link=&quot;probit&quot; ) dat&lt;-get_population_data(sim_dat) dat$seen &lt;- dat$occurrence* dat$observation sim_dat_R&lt;-simulate_population( seed=224, data_structure = ds, n_response=2, response_names = c(&quot;occurrence&quot;,&quot;observation&quot;), parameters = list( intercept= c(-3,0), residual=list(vcov=c(4,0)) ), family= &quot;binomial&quot;, link=&quot;probit&quot; ) dat_R&lt;-get_population_data(sim_dat_R) dat_R$seen &lt;- dat_R$occurrence* dat_R$observation par(mfrow=c(1,2)) plot(y~x,locations2, pch=19, col=dat$occurrence) points(y~x,locations2[dat$seen==1,], pch=19, col=&quot;yellow&quot;, cex=0.5) plot(y~x,locations2, pch=19, col=dat_R$occurrence) points(y~x,locations2[dat_R$seen==1,], pch=19, col=&quot;yellow&quot;, cex=0.5) "],["7-sampling.html", "7 Sampling", " 7 Sampling To create different sampling schemes, we can use the sample arguments in the simulate_population() function, for example: sample_type = &quot;nested&quot;, sample_param = cbind(individual=c(10, 15),observation=c(10, 5)), There are three different types of sampling ‘nested’, ‘missing’ and ‘temporal’, each of which are outlined below. The sample arguments create different datasets for each population that has been simulated, and you can then use the function get_sample_data() to extract the sampled data. "],["7.1-nested.html", "7.1 Nested", " 7.1 Nested Nested sampling assumes that you have a nested structure, and allows you to sample different numbers at each hierarchical level. The param input is a matrix with (named) columns. The rows of this matrix represent different sampling sets. This is most easily put together using the cbind() (column bind) function, specifying the names. The number of repeat observations for a higher level can be specified using name ‘observation’ (this doesn’t have to exist in the data structure). For example cbind(individual=c(10, 15),observation=c(10, 5)) ## individual observation ## [1,] 10 10 ## [2,] 15 5 would represent sampling the data structure above, the first set having 10 individuals each with 10 observations Note this sampling procedure only produces balanced sampling designs. For unbalanced designs see ‘missing data’ below. 7.1.1 Worked example 1 We want to see how the number of repeat measurements on individuals affects power. In order to vary the number of observations of an individual, we could specify: param &lt;- cbind(nest=10,individual=10,observation=c(20, 10, 5, 2)) pop_data &lt;- simulate_population( data_structure = make_structure(&quot;nest(10)/individual(20)&quot;,repeat_obs=20), parameters = list( individual = list( vcov = 0.1 ), observation= list( names = c(&quot;environment&quot;), beta =c(0.5) ), residual = list( vcov = 0.8 ) ), sample_type = &quot;nested&quot;, sample_param = param ) To extract the sampled data we can then use get_sample_data() specifying which sample set we want, for example the second set 10 nests, each with 10 individuals with 10 observations: sample_data &lt;- get_sample_data(pop_data, sample_set=2) length(unique(sample_data$nest)) ## [1] 10 length(unique(sample_data$individual)) ## [1] 100 nrow(sample_data) ## [1] 1000 "],["7.2-missing-data.html", "7.2 Missing data", " 7.2 Missing data The missing data methods allows generation of unbalanced data. Missing data is generated through creating probabilities of being sampled using logistic regression. Missingness can then either be random, or a function of any of the simulated variables. This methods allows the different classes of missing data to be generated: Missing Completely At Random (MCAR) All observations have an equal probability of being sampled Missing At Random (MAR) Probability of missingness is dependent on variables correlated with the response variable (i.e. a predictor variable) Missing Not At Random (MNAR) Probability of missingness is dependent on the response variable itself 7.2.1 MCAR Missing completely at random occurs when the probability of missingness is not dependent on anything. This can be implemented through a logistic regression, where only the intercept is specified: \\[ logit(p) = beta_0 \\] Note this intercept is on the logit scale, so 0 is equivalent to 0.5. pop_data &lt;- simulate_population( data_structure = make_structure(&quot;individual(100)&quot;,repeat_obs=5), parameters = list( individual = list( vcov = 0.1 ), observation= list( names = c(&quot;environment&quot;), beta =c(0.5) ), residual = list( vcov = 0.8 ) ), sample_type = &quot;missing&quot;, sample_param = &quot;0&quot; ) sample_data &lt;- get_sample_data(pop_data) nrow(sample_data) ## [1] 244 7.2.2 MAR Missing at random occurs when the probability of missingness is dependent on a predictor variable (or a variables correlated with y). This can be implemented through a logistic regression, where the predictor variable(s) is a predictor(s) of y: \\[ logit(p) = beta_0 + beta_1*environment \\] pop_data &lt;- simulate_population( data_structure = make_structure(&quot;individual(100)&quot;,repeat_obs=5), parameters = list( individual = list( vcov = 0.1 ), observation= list( names = c(&quot;environment&quot;), beta =c(0.5) ), residual = list( vcov = 0.8 ) ), sample_type = &quot;missing&quot;, sample_param = &quot;0.5*environment&quot; ) sample_data &lt;- get_sample_data(pop_data) nrow(sample_data) ## [1] 239 The predictor variables are scaled (mean 0, variance 1), so the slopes are directly comparable across traits, and intercept represents the mean (on the logit scale). 7.2.3 MNAR Missing not at random occurs when the probability of missingness is dependent on the response variable itself variable (i.e. y). This can be implemented through a logistic regression, where the predictor variable is y: \\[ logit(p) = beta_0 + beta_1*y \\] Again y is scaled. pop_data &lt;- simulate_population( data_structure = make_structure(&quot;individual(100)&quot;,repeat_obs=5), parameters = list( individual = list( vcov = 0.8 ), observation= list( names = c(&quot;environment&quot;), beta =c(0.1) ), residual = list( vcov = 0.5 ) ), sample_type = &quot;missing&quot;, sample_param = &quot;0.5*y&quot; ) sample_data &lt;- get_sample_data(pop_data) nrow(sample_data) ## [1] 262 Lets try and visualise this. We know there is lots f between individual variation, and we know sampling is based on phenotype, so we would expect an association between number of observations and phenotype: ind_data &lt;- data.frame( n=as.vector(table(sample_data$individual)), mean=tapply(sample_data$y,sample_data$individual,mean) ) boxplot(mean~n,ind_data) "],["7.3-temporal-sampling.html", "7.3 Temporal Sampling", " 7.3 Temporal Sampling In the parameters we specify a list, with the temporal variable time, the grouping variable with which the temporal sampling occurs group, the between group variance (as a proportion) in sampling times variance and the within group sample size n: pop_data &lt;- simulate_population( data_structure = make_structure(&quot;day(100) + individual(100)&quot;,repeat_obs=1), parameters = list( individual = list( vcov = 0.1 ), day=list( covariate=TRUE, beta=0.4 ), residual = list( vcov = 0.8 ) ), sample_type = &quot;temporal&quot;, sample_param = list( time = c(&quot;day&quot;), group = c(&quot;individual&quot;), variance = c(0.1,0.2), n=4), ) sample_data &lt;- get_sample_data(pop_data) "],["8-other-model-types.html", "8 Other model Types ", " 8 Other model Types "],["8.1-double-hierarchical-models-dhglms.html", "8.1 Double hierarchical models (DHGLMs)", " 8.1 Double hierarchical models (DHGLMs) 8.1.1 DHGLM squid_data &lt;- simulate_population( data_structure=make_structure(&quot;individual(50)&quot;,N=10), parameters = list( individual = list( names = c(&quot;ind_int&quot;,&quot;ind_slopes&quot;,&quot;ind_lnsd&quot;), mean =c(0, 0, 0.5), vcov = c(0.5, 0.1, 0.1), beta = c(1, 0, 0), functions=c(NA,NA,&quot;exp&quot;) ), observation =list( names=&quot;environment&quot;, beta=0.2 ), residual = list( vcov = 1, beta = 0 ), interactions = list( names = c(&quot;ind_slopes:environment&quot;,&quot;ind_lnsd:residual&quot;), beta = c(1, 1) ) ) ) 8.1.2 Bivariate DHGLM squid_data &lt;- simulate_population( n_response=2, parameters = list( individual = list( names = c(&quot;ind_int1&quot;,&quot;ind_slopes1&quot;,&quot;ind_lnsd1&quot;,&quot;ind_int2&quot;,&quot;ind_slopes2&quot;,&quot;ind_lnsd2&quot;), mean =c(0, 0, 0.5,0,0,1), vcov = c(0.5,0.1,0.1,0.4,0.2,0.05), beta = matrix(c( 1,0, 0,0, 0,0, 0,1, 0,0, 0,0 ), byrow=TRUE,ncol=2), functions=c(NA,NA,&quot;exp&quot;,NA,NA,&quot;exp&quot;) ), observation =list( names=&quot;environment&quot;, beta=matrix(c(0.2,-0.3),ncol=2) ), residual = list( names = c(&quot;residual1&quot;,&quot;residual2&quot;), vcov = c(1,1), beta = matrix(c(0,0,0,0),ncol=2) ), interactions = list( names = c(&quot;ind_slopes1:environment&quot;,&quot;ind_lnsd1:residual1&quot;,&quot;ind_slopes2:environment&quot;,&quot;ind_lnsd2:residual2&quot;), beta = matrix(c(1,1,0,0,0,0,1,1),byrow=TRUE,ncol=2) ) ), data_structure=make_structure(&quot;individual(50)&quot;,N=10) ) "],["8.2-zero-inflated-poisson.html", "8.2 Zero-inflated Poisson", " 8.2 Zero-inflated Poisson squidSim doesn’t generate zero-inflated data directly, but it can be easily made. For example, we can simulate a Poisson variable and a binomial variable, and multiply them together to get our zero-inflated response. squid_data &lt;- simulate_population( make_structure(structure = &quot;mother(100)&quot;,repeat_obs=5), n_response = 2, response_names = c(&quot;reproduction&quot;,&quot;survival&quot;), parameters=list( intercept = c(1,0), mother = list( vcov = matrix(c( 0.25,0.15, 0.15,1 ),nrow=2,ncol=2,byrow=TRUE) ), residual = list( vcov = matrix(c( 0.25,0.15, 0.15,1 ),nrow = 2,ncol = 2,byrow=TRUE), beta = matrix(c( 1,0, 0,0 ),nrow = 2,ncol = 2,byrow=TRUE) ) ), family=c(&quot;poisson&quot;,&quot;binomial&quot;), link=c(&quot;log&quot;,&quot;probit&quot;) ) data &lt;- get_population_data(squid_data) data$y &lt;- data$survival * data$reproduction head(data,10) ## reproduction survival mother_effect1 mother_effect2 residual1 residual2 ## 1 6 0 1.2400171 1.17829778 -0.687284900 0.1006170 ## 2 23 1 1.2400171 1.17829778 0.848319584 -1.3063138 ## 3 13 1 1.2400171 1.17829778 -0.350498912 -0.9775361 ## 4 7 0 1.2400171 1.17829778 -0.872358752 -0.7551186 ## 5 7 1 1.2400171 1.17829778 0.005561232 -0.7604861 ## 6 10 1 0.3912797 -0.01031889 1.353984498 1.1636901 ## 7 4 1 0.3912797 -0.01031889 -0.325840994 0.4764468 ## 8 6 1 0.3912797 -0.01031889 -0.108594655 1.4663695 ## 9 16 1 0.3912797 -0.01031889 1.264513662 0.7186276 ## 10 6 1 0.3912797 -0.01031889 0.293968466 -0.3986855 ## mother squid_pop y ## 1 1 1 0 ## 2 1 1 23 ## 3 1 1 13 ## 4 1 1 0 ## 5 1 1 7 ## 6 2 1 10 ## 7 2 1 4 ## 8 2 1 6 ## 9 2 1 16 ## 10 2 1 6 plot(table(data$y)) "],["9-power.html", "9 Conducting a power analysis using squidSim", " 9 Conducting a power analysis using squidSim Simulations are useful for many reasons. For more complex models they may well be used to conduct power analyses, as it is difficult to derive the sampling distribution of a given parameter analytically. Here, we provide a simple example of a power analysis. {squidSim} doesn’t perform power analyses as part of the package, but the simulated datasets can easily be used for this. There are may stages to a power analysis, and the first ones relates to working out how the data should be structured, and what parameters are of interest, and what effect sizes are of interest, and so how a simulation should be parametrised. We do not cover this here, simply we provide a worked example of doing a power analysis, once we have worked those things out. Here we take a fictional example, where we are interested in working out the power to detect a repeatability (proportion of total variance) among individuals of 0.2. We have a data structure that includes repeated measures of individual across years. The first step in the simulation procedure is to simulate many datasets. We can easily to this using the n_pop argument in simulate_population(): library(squidSim) ## generate a data structure, here 100 individuals measured in each of 10 years ds &lt;- make_structure(&quot;individual(20) + year(10)&quot;) squid_data &lt;- simulate_population( data_structure = ds, parameters = list( individual = list( vcov = 0.2 ## effect size of interest ), year = list( vcov = 0.3 ), residual = list( vcov = 0.5 ) ), n_pop = 1000 ) We can then extract our individual datasets as a list for more easy processing: sim_data &lt;- get_population_data(squid_data, list=TRUE) We can then run our model or models of interest across each of the datasets and then extract the parameter of interest. With a power analysis, typically this is a p-value for a given parameter, but might be another parameter such as a variance, if building a sampling distribution. Here, I will use a likelihood ratio test to derive a p-value between a model that does estimate among individual variance and ones that does not. To efficiently run the models across all datasets, we need a little more coding. You can use loops, here I will use the *apply functions. sapply applies a function to each element of the list (here I call that element dat), and then returns a vector or matrix of the output of each (here the p-value from the likelihood ratio test). # dat&lt;-sim_data[[1]] models_out &lt;- sapply(sim_data, function(dat){ mod1 &lt;- lme4::lmer(y ~ 1 + (1|year) + (1|individual), dat,REML=FALSE) mod2 &lt;- lme4::lmer(y ~ 1 + (1|year) , dat,REML=FALSE) anova(mod1,mod2)[&quot;Pr(&gt;Chisq)&quot;][[1]][2] }) ## Warning in checkConv(attr(opt, &quot;derivs&quot;), opt$par, ctrl = control$checkConv, : ## Model failed to converge with max|grad| = 0.00226498 (tol = 0.002, component 1) ## Warning in checkConv(attr(opt, &quot;derivs&quot;), opt$par, ctrl = control$checkConv, : ## Model failed to converge with max|grad| = 0.00228789 (tol = 0.002, component 1) ## boundary (singular) fit: see help(&#39;isSingular&#39;) With this vector of p-values, I can then calculate the power. Power is defined as the probability of finding a significant results when there is a true effect. To estimate this, we can look at the proportion of the tests that give a p-value of &lt;0.05: mean(models_out&lt;0.05) ## [1] 0.997 "]]
